{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqyDubJLYkvVgudSAROKNh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ennie191/NetraAI/blob/main/NetrAi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "LRWVUskOuoVo",
        "outputId": "fe8839d9-3f98-4473-93f6-8abf8008b196"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6c38225e-ee0f-4bd0-94bc-e06e4c9448fe\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6c38225e-ee0f-4bd0-94bc-e06e4c9448fe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload() # Choose the kaggle.json file you downloaded\n",
        "\n",
        "# Make directory to store the key\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c aptos2019-blindness-detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBRZVzU5vyfm",
        "outputId": "2e19e181-e01b-43d6-a094-9061cb20cc0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "429 Client Error: Too Many Requests for url: https://www.kaggle.com/api/v1/competitions/data/download-all/aptos2019-blindness-detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q aptos2019-blindness-detection.zip -d ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JFqMEFGxGGm",
        "outputId": "d19a4f09-3658-4504-c7c9-17e8b000bd2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open aptos2019-blindness-detection.zip, aptos2019-blindness-detection.zip.zip or aptos2019-blindness-detection.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK4NLaprxpgG",
        "outputId": "7c256d31-9fb1-4642-d800-29c4166bca66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c aptos2019-blindness-detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYfWCss3xuzX",
        "outputId": "042f9e49-a3a8-4036-997e-3c2e570a7ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "429 Client Error: Too Many Requests for url: https://www.kaggle.com/api/v1/competitions/data/download-all/aptos2019-blindness-detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U2bBx6Tx8G6",
        "outputId": "cbda2e25-d171-4286-f993-4f5e8e2fc394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thdbCWtNyPgD",
        "outputId": "592a68e5-e54c-425c-d18a-1cf28204eafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/My\\ Drive/Kaggle/APTOS2019"
      ],
      "metadata": {
        "id": "nxJ4SI-hzeZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My\\ Drive/Kaggle/APTOS2019"
      ],
      "metadata": {
        "id": "ACb9aNt3zh7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download just the csv file\n",
        "!kaggle competitions download -c aptos2019-blindness-detection -f train.csv"
      ],
      "metadata": {
        "id": "_ilhDsVFzkcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import time # Import the time library\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 1. SETUP THE ENVIRONMENT ---\n",
        "# This just confirms your location, no need to remount\n",
        "KAGGLE_DIR = \"/content/drive/My Drive/Kaggle/APTOS2019_Subset\"\n",
        "%cd $KAGGLE_DIR\n",
        "print(f\"Current directory: {os.getcwd()}\")\n",
        "\n",
        "\n",
        "# --- 2. DOWNLOAD THE DATA SUBSET (WITH DELAY) ---\n",
        "\n",
        "# Load the csv to get the image names\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "# --- How many images to download? ---\n",
        "NUM_IMAGES_TO_DOWNLOAD = 500\n",
        "# -----------------------------------\n",
        "\n",
        "# Get the list of the first 500 image filenames\n",
        "image_list = df['id_code'].head(NUM_IMAGES_TO_DOWNLOAD).tolist()\n",
        "\n",
        "# Ensure the 'train_images' directory exists\n",
        "os.makedirs('train_images', exist_ok=True)\n",
        "\n",
        "# Loop through the list and download each image one by one\n",
        "print(f\"\\nStarting download of {NUM_IMAGES_TO_DOWNLOAD} images (with delay to avoid errors)...\")\n",
        "for i, image_id in enumerate(image_list):\n",
        "    filename = f\"{image_id}.png\"\n",
        "    filepath = os.path.join('train_images', filename)\n",
        "\n",
        "    # Only download if the file doesn't already exist\n",
        "    if not os.path.exists(filepath):\n",
        "        # Use the -p flag to specify the output path and --quiet to reduce output\n",
        "        !kaggle competitions download -c aptos2019-blindness-detection -f train_images/{filename} -p train_images --quiet\n",
        "\n",
        "        # --- THIS IS THE FIX ---\n",
        "        # Pause for 1 second to respect the API rate limit\n",
        "        time.sleep(1)\n",
        "\n",
        "    # Print progress every 25 images\n",
        "    if (i + 1) % 25 == 0:\n",
        "        print(f\"  Downloaded {i + 1} / {NUM_IMAGES_TO_DOWNLOAD} images...\")\n",
        "\n",
        "\n",
        "print(\"\\n✅ Download of image subset complete!\")"
      ],
      "metadata": {
        "id": "Oai4Am2g5c8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Import Libraries and Load Data\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the base directory where your data is stored\n",
        "DATA_DIR = \"/content/drive/My Drive/Kaggle/APTOS2019_Subset\"\n",
        "TRAIN_IMG_DIR = os.path.join(DATA_DIR, \"train_images\")\n",
        "\n",
        "# Load the csv file\n",
        "df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
        "\n",
        "# We are only using the first 500 images we downloaded\n",
        "df_subset = df.head(500)\n",
        "\n",
        "# Create a new column with the full path to each image\n",
        "df_subset['image_path'] = df_subset['id_code'].apply(lambda x: os.path.join(TRAIN_IMG_DIR, f'{x}.png'))\n",
        "\n",
        "# Split the data into training (80%) and validation (20%) sets\n",
        "train_df, val_df = train_test_split(\n",
        "    df_subset,\n",
        "    test_size=0.2,      # 20% of the data will be used for validation\n",
        "    random_state=42,    # Ensures the split is the same every time\n",
        "    stratify=df_subset['diagnosis'] # Ensures the proportion of each class is the same in both sets\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_df)}\")\n",
        "print(f\"Validation samples: {len(val_df)}\")\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "MiUgZ35Q_i02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Create TensorFlow Datasets\n",
        "IMG_SIZE = 224 # The standard input size for MobileNet\n",
        "BATCH_SIZE = 32 # How many images to process at once\n",
        "\n",
        "def load_and_preprocess_image(path, label):\n",
        "    # Read the image file\n",
        "    image = tf.io.read_file(path)\n",
        "    # Decode the image to a tensor\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    # Resize the image to our desired size\n",
        "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "    # Normalize pixel values from [0, 255] to [0, 1]\n",
        "    image = image / 255.0\n",
        "    return image, label\n",
        "\n",
        "# Create the training dataset\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_df['image_path'].values, train_df['diagnosis'].values))\n",
        "train_ds = train_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.shuffle(buffer_size=len(train_df)).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Create the validation dataset\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_df['image_path'].values, val_df['diagnosis'].values))\n",
        "val_ds = val_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"✅ Datasets created successfully.\")"
      ],
      "metadata": {
        "id": "P0dDYWhW_pFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Build the Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define data augmentation\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomContrast(0.2),\n",
        "], name=\"data_augmentation\")\n",
        "\n",
        "# Define the input shape\n",
        "input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "# Get the pre-trained base model\n",
        "base_model = tf.keras.applications.MobileNetV3Small(\n",
        "    input_shape=input_shape,\n",
        "    include_top=False, # We don't need the final classification layer from the original model\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# Freeze the base model so its weights are not updated during initial training\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create the final model by adding our own layers on top of the base model\n",
        "inputs = keras.Input(shape=input_shape)\n",
        "x = data_augmentation(inputs) # Apply augmentation\n",
        "x = base_model(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.2)(x) # Helps prevent overfitting\n",
        "outputs = layers.Dense(5, activation='softmax')(x) # 5 classes for DR (0-4)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss='sparse_categorical_crossentropy', # Use this loss function for integer labels\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Print a summary of our model architecture\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zNkV1cws_r7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Train the Model\n",
        "EPOCHS = 20\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "print(\"\\n🎉 Model training complete!\")"
      ],
      "metadata": {
        "id": "wIlDdXnq__iW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell to Fix the DataFrame\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the directories\n",
        "DATA_DIR = \"/content/drive/My Drive/Kaggle/APTOS2019_Subset\"\n",
        "TRAIN_IMG_DIR = os.path.join(DATA_DIR, \"train_images\")\n",
        "\n",
        "# 1. Get the list of filenames that were actually downloaded\n",
        "downloaded_images = os.listdir(TRAIN_IMG_DIR)\n",
        "# Clean up the names to get the id_code (e.g., 'xyz.png' -> 'xyz')\n",
        "downloaded_ids = [img.replace('.png', '') for img in downloaded_images]\n",
        "\n",
        "# 2. Load the original full CSV\n",
        "full_df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
        "\n",
        "# 3. Filter the full DataFrame to ONLY include rows for the images we have\n",
        "# This is the crucial step\n",
        "df_correct = full_df[full_df['id_code'].isin(downloaded_ids)].copy()\n",
        "\n",
        "# 4. Create the full image path again\n",
        "df_correct['image_path'] = df_correct['id_code'].apply(lambda x: os.path.join(TRAIN_IMG_DIR, f'{x}.png'))\n",
        "\n",
        "# 5. Re-run the train-test split on the corrected DataFrame\n",
        "train_df, val_df = train_test_split(\n",
        "    df_correct,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df_correct['diagnosis']\n",
        ")\n",
        "\n",
        "print(\"✅ DataFrame has been corrected based on actual downloaded files.\")\n",
        "print(f\"New training samples: {len(train_df)}\")\n",
        "print(f\"New validation samples: {len(val_df)}\")"
      ],
      "metadata": {
        "id": "q_Y9lMqSAOow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell to find and remove ALL bad images by verifying them\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm # To show a nice progress bar\n",
        "\n",
        "# Define the directory where your images are stored\n",
        "TRAIN_IMG_DIR = \"/content/drive/My Drive/Kaggle/APTOS2019_Subset/train_images\"\n",
        "\n",
        "bad_files = []\n",
        "print(f\"Deep scanning {len(os.listdir(TRAIN_IMG_DIR))} files in {TRAIN_IMG_DIR}...\")\n",
        "\n",
        "# Loop through all downloaded images with a progress bar\n",
        "for filename in tqdm(os.listdir(TRAIN_IMG_DIR)):\n",
        "    filepath = os.path.join(TRAIN_IMG_DIR, filename)\n",
        "\n",
        "    try:\n",
        "        # Attempt to open the image file\n",
        "        img = Image.open(filepath)\n",
        "        # Verify that the image data can be read\n",
        "        img.verify()\n",
        "    except Exception as e:\n",
        "        # If any error occurs, the file is corrupted\n",
        "        print(f\"Found corrupted file: {filename}, Error: {e}\")\n",
        "        bad_files.append(filepath)\n",
        "\n",
        "# Report and delete the corrupted files\n",
        "if len(bad_files) > 0:\n",
        "    print(f\"\\nFound {len(bad_files)} corrupted files. Deleting them now...\")\n",
        "    for file_to_delete in bad_files:\n",
        "        print(f\"  - Deleting {os.path.basename(file_to_delete)}\")\n",
        "        os.remove(file_to_delete)\n",
        "    print(\"\\n✅ All corrupted files have been removed.\")\n",
        "else:\n",
        "    print(\"\\n✅ No corrupted files found during deep scan.\")"
      ],
      "metadata": {
        "id": "3MPWOZuRAqjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Create and move to the new directory\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive if not already mounted\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define and create the new directory for the full dataset\n",
        "FULL_DATA_DIR = \"/content/drive/My Drive/Kaggle/APTOS2019_Full\"\n",
        "os.makedirs(FULL_DATA_DIR, exist_ok=True)\n",
        "\n",
        "# Change the current directory to the new folder\n",
        "%cd $FULL_DATA_DIR\n",
        "\n",
        "print(f\"✅ Successfully moved to: {os.getcwd()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNJNWNVgEgNR",
        "outputId": "bf7a4a19-25ec-4198-e802-565eae36cd05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Kaggle/APTOS2019_Full\n",
            "✅ Successfully moved to: /content/drive/My Drive/Kaggle/APTOS2019_Full\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell to correctly configure the Kaggle API key\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# --- 1. DEFINE THE OFFICIAL KAGGLE DIRECTORY ---\n",
        "KAGGLE_CONFIG_DIR = os.path.join(os.path.expanduser(\"~\"), \".kaggle\")\n",
        "# This resolves to /root/.kaggle/ in Colab\n",
        "\n",
        "# --- 2. DEFINE THE PATH TO YOUR API KEY ---\n",
        "# Assumes your kaggle.json is in your current Google Drive folder\n",
        "# e.g., /content/drive/My Drive/Kaggle/IDRiD_Dataset/kaggle.json\n",
        "API_KEY_PATH = \"kaggle.json\"\n",
        "\n",
        "# --- 3. CHECK FOR AND UPLOAD THE KEY IF NEEDED ---\n",
        "if not os.path.exists(API_KEY_PATH):\n",
        "    print(\"Could not find kaggle.json in the current directory.\")\n",
        "    print(\"Please upload your kaggle.json API key:\")\n",
        "    files.upload() # Prompt to upload the file\n",
        "\n",
        "# --- 4. CREATE THE DIRECTORY AND COPY THE KEY ---\n",
        "os.makedirs(KAGGLE_CONFIG_DIR, exist_ok=True)\n",
        "!cp {API_KEY_PATH} {KAGGLE_CONFIG_DIR}\n",
        "\n",
        "# --- 5. SET SECURE PERMISSIONS ---\n",
        "# This step is required by the Kaggle API\n",
        "!chmod 600 {os.path.join(KAGGLE_CONFIG_DIR, \"kaggle.json\")}\n",
        "\n",
        "print(f\"\\n✅ Kaggle API key has been successfully configured at: {KAGGLE_CONFIG_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f10DkSkyEgKq",
        "outputId": "b75a76ac-1437-4816-f4b0-bc94f3609201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Kaggle API key has been successfully configured at: /root/.kaggle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell to run after manual upload is complete\n",
        "import os\n",
        "\n",
        "# Define and move to the correct directory\n",
        "FULL_DATA_DIR = \"/content/drive/My Drive/Kaggle/APTOS2019_Full\"\n",
        "%cd $FULL_DATA_DIR\n",
        "\n",
        "# 1. Verify the file exists (you should see the .zip file listed)\n",
        "print(\"Verifying file presence...\")\n",
        "!ls -lh\n",
        "\n",
        "# 2. Unzip the file\n",
        "print(\"\\nUnzipping the dataset... this will take several minutes.\")\n",
        "!unzip -q aptos2019-blindness-detection.zip\n",
        "\n",
        "print(\"\\n✅ Unzip complete! All images are now ready for training.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyLTHvklEgEL",
        "outputId": "58cbcd7f-1475-49b5-ba8a-b4dd04209278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Kaggle/APTOS2019_Full\n",
            "Verifying file presence...\n",
            "total 9.6G\n",
            "-rw------- 1 root root 9.6G Oct 19 16:05 aptos2019-blindness-detection.zip\n",
            "-rw------- 1 root root   64 Oct 19 15:26 kaggle.json\n",
            "-rw------- 1 root root  29K Dec 18  2019 sample_submission.csv\n",
            "-rw------- 1 root root  25K Dec 18  2019 test.csv\n",
            "drwx------ 2 root root 4.0K Oct 19 16:39 test_images\n",
            "-rw------- 1 root root  54K Dec 18  2019 train.csv\n",
            "drwx------ 2 root root 4.0K Oct 19 16:41 train_images\n",
            "\n",
            "Unzipping the dataset... this will take several minutes.\n",
            "replace sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
            "✅ Unzip complete! All images are now ready for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Prepare the Full Dataset\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the base directory for the full dataset\n",
        "DATA_DIR = \"/content/drive/My Drive/Kaggle/APTOS2019_Full\"\n",
        "TRAIN_IMG_DIR = os.path.join(DATA_DIR, \"train_images\")\n",
        "\n",
        "# Load the csv file\n",
        "df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
        "\n",
        "# Create a new column with the full path to each image\n",
        "df['image_path'] = df['id_code'].apply(lambda x: os.path.join(TRAIN_IMG_DIR, f'{x}.png'))\n",
        "\n",
        "# Split the data into training (80%) and validation (20%) sets\n",
        "train_df, val_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['diagnosis'] # Stratify to maintain class balance\n",
        ")\n",
        "\n",
        "# --- Create TensorFlow Datasets ---\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def load_and_preprocess_image(path, label):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "    image = image / 255.0\n",
        "    return image, label\n",
        "\n",
        "# Create the training dataset\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_df['image_path'].values, train_df['diagnosis'].values))\n",
        "train_ds = train_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.shuffle(buffer_size=len(train_df)).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# Create the validation dataset\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_df['image_path'].values, val_df['diagnosis'].values))\n",
        "val_ds = val_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"✅ Full dataset is ready for training.\")\n",
        "print(f\"Total training samples: {len(train_df)}\")\n",
        "print(f\"Total validation samples: {len(val_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-e0f7joYCRk",
        "outputId": "5cafe32a-3dd7-49ea-a5c1-fb6a332905eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Full dataset is ready for training.\n",
            "Total training samples: 2929\n",
            "Total validation samples: 733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell to calculate class weights\n",
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Use the full training dataframe to calculate weights\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(train_df['diagnosis']),\n",
        "    y=train_df['diagnosis'].values\n",
        ")\n",
        "\n",
        "# Create a dictionary mapping class indices to their calculated weights\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "print(\"Class Weights have been calculated to penalize the model for misclassifying rare classes:\")\n",
        "print(class_weight_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gob7up8SnpFA",
        "outputId": "5949de69-5375-46f8-b971-1f6166b74df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights have been calculated to penalize the model for misclassifying rare classes:\n",
            "{0: np.float64(0.4056786703601108), 1: np.float64(1.979054054054054), 2: np.float64(0.7331664580725907), 3: np.float64(3.803896103896104), 4: np.float64(2.4822033898305085)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Prepare Data for Binary Classification\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Define the base directory for the full dataset\n",
        "DATA_DIR = \"/content/drive/My Drive/Kaggle/APTOS2019_Full\"\n",
        "TRAIN_IMG_DIR = os.path.join(DATA_DIR, \"train_images\")\n",
        "\n",
        "# Load the csv file\n",
        "df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
        "\n",
        "# --- THIS IS THE KEY CHANGE ---\n",
        "# Create a new binary label column.\n",
        "# If diagnosis is 0, the new label is 0.\n",
        "# If diagnosis is > 0 (1, 2, 3, or 4), the new label is 1.\n",
        "df['binary_diagnosis'] = df['diagnosis'].apply(lambda x: 1 if x > 0 else 0)\n",
        "print(\"Created new binary labels:\")\n",
        "print(df['binary_diagnosis'].value_counts())\n",
        "# -----------------------------\n",
        "\n",
        "# Create a new column with the full path to each image\n",
        "df['image_path'] = df['id_code'].apply(lambda x: os.path.join(TRAIN_IMG_DIR, f'{x}.png'))\n",
        "\n",
        "# Split the data, stratifying on the NEW binary label\n",
        "train_df, val_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['binary_diagnosis']\n",
        ")\n",
        "\n",
        "# --- Define IMG_SIZE and BATCH_SIZE ---\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# --- Create TensorFlow Datasets (without normalization for EfficientNet) ---\n",
        "def load_and_preprocess_image(path, label):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "    return image, label\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_df['image_path'].values, train_df['binary_diagnosis'].values))\n",
        "train_ds = train_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.shuffle(buffer_size=len(train_df)).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_df['image_path'].values, val_df['binary_diagnosis'].values))\n",
        "val_ds = val_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# --- Calculate Class Weights for the binary problem ---\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(train_df['binary_diagnosis']),\n",
        "    y=train_df['binary_diagnosis'].values\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "print(\"\\nClass weights for the binary problem:\")\n",
        "print(class_weight_dict)\n",
        "print(\"\\n✅ Binary dataset is ready for training.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U68emcaTYp7",
        "outputId": "23b00307-b72a-40c1-fdf5-3497999033f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new binary labels:\n",
            "binary_diagnosis\n",
            "1    1857\n",
            "0    1805\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class weights for the binary problem:\n",
            "{0: np.float64(1.014196675900277), 1: np.float64(0.9861952861952862)}\n",
            "\n",
            "✅ Binary dataset is ready for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Build and Train the Binary Model (with keep-alive + autosave)\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import threading, time, os\n",
        "import tensorflow as tf\n",
        "\n",
        "# --- Keep-Alive Thread ---\n",
        "def keep_alive():\n",
        "    while True:\n",
        "        time.sleep(120)  # every 2 minutes\n",
        "        print(\"✅ Still running...\")\n",
        "\n",
        "threading.Thread(target=keep_alive, daemon=True).start()\n",
        "\n",
        "# --- Mount Drive (optional but recommended) ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "SAVE_PATH = '/content/drive/MyDrive/binary_model_checkpoint.keras'\n",
        "\n",
        "# --- 1. BUILD THE MODEL for Binary Classification ---\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "], name=\"data_augmentation\")\n",
        "\n",
        "input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
        "base_model = tf.keras.applications.EfficientNetB0(\n",
        "    input_shape=input_shape,\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = keras.Input(shape=input_shape)\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# --- 2. COMPILE & TRAIN THE TOP LAYER ONLY ---\n",
        "print(\"--- Phase 1: Training the Classifier Head ---\")\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    SAVE_PATH, save_best_only=True\n",
        ")\n",
        "\n",
        "history_phase1 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[checkpoint_cb]\n",
        ")\n",
        "\n",
        "# --- 3. PREPARE FOR FINE-TUNING ---\n",
        "print(\"\\n--- Phase 2: Preparing for Fine-Tuning ---\")\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-60]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# --- 4. FINE-TUNE THE MODEL ---\n",
        "print(\"\\n--- Phase 2: Starting Fine-Tuning ---\")\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=5, restore_best_weights=True\n",
        ")\n",
        "\n",
        "history_phase2 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    initial_epoch=history_phase1.epoch[-1] + 1,\n",
        "    epochs=30,\n",
        "    callbacks=[early_stopping, checkpoint_cb],\n",
        "    class_weight=class_weight_dict\n",
        ")\n",
        "\n",
        "print(\"\\n🎉 Binary model fine-tuning complete! Check Drive for autosaved checkpoints.\")\n",
        "\n",
        "# --- 5. VISUALIZE COMBINED RESULTS ---\n",
        "acc = history_phase1.history['accuracy'] + history_phase2.history['accuracy']\n",
        "val_acc = history_phase1.history['val_accuracy'] + history_phase2.history['val_accuracy']\n",
        "loss = history_phase1.history['loss'] + history_phase2.history['loss']\n",
        "val_loss = history_phase1.history['val_loss'] + history_phase2.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.axvline(x=len(history_phase1.history['accuracy']) - 1, color='r', linestyle='--', label='Start of Fine-Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.axvline(x=len(history_phase1.history['accuracy']) - 1, color='r', linestyle='--', label='Start of Fine-Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mCXQrJu69wy",
        "outputId": "e5c96454-b258-46f9-e8cf-49417541a1b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "--- Phase 1: Training the Classifier Head ---\n",
            "Epoch 1/10\n",
            "✅ Still running...\n",
            "✅ Still running...\n",
            "\u001b[1m38/92\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:08\u001b[0m 2s/step - accuracy: 0.6997 - loss: 0.5920✅ Still running...\n",
            "\u001b[1m89/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.7758 - loss: 0.5077✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7786 - loss: 0.5040✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m607s\u001b[0m 4s/step - accuracy: 0.7795 - loss: 0.5028 - val_accuracy: 0.8854 - val_loss: 0.3273\n",
            "Epoch 2/10\n",
            "✅ Still running...\n",
            "✅ Still running...\n",
            "\u001b[1m34/92\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 2s/step - accuracy: 0.9127 - loss: 0.2502✅ Still running...\n",
            "\u001b[1m88/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.9174 - loss: 0.2434 ✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m586s\u001b[0m 3s/step - accuracy: 0.9178 - loss: 0.2426 - val_accuracy: 0.9400 - val_loss: 0.2398\n",
            "Epoch 3/10\n",
            "✅ Still running...\n",
            "✅ Still running...\n",
            "✅ Still running...\n",
            "\u001b[1m53/92\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 2s/step - accuracy: 0.9379 - loss: 0.2007✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9396 - loss: 0.1948✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m588s\u001b[0m 4s/step - accuracy: 0.9396 - loss: 0.1948 - val_accuracy: 0.9550 - val_loss: 0.1970\n",
            "Epoch 4/10\n",
            "✅ Still running...\n",
            "✅ Still running...\n",
            "\u001b[1m 3/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:23\u001b[0m 2s/step - accuracy: 0.9253 - loss: 0.1593✅ Still running...\n",
            "\u001b[1m57/92\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:18\u001b[0m 2s/step - accuracy: 0.9557 - loss: 0.1518✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9534 - loss: 0.1573✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m556s\u001b[0m 3s/step - accuracy: 0.9533 - loss: 0.1574 - val_accuracy: 0.9563 - val_loss: 0.1811\n",
            "Epoch 5/10\n",
            "✅ Still running...\n",
            "✅ Still running...\n",
            "\u001b[1m17/92\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:40\u001b[0m 2s/step - accuracy: 0.9586 - loss: 0.1437✅ Still running...\n",
            "\u001b[1m71/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.9535 - loss: 0.1521✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9528 - loss: 0.1528✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m570s\u001b[0m 3s/step - accuracy: 0.9528 - loss: 0.1529 - val_accuracy: 0.9604 - val_loss: 0.1672\n",
            "Epoch 6/10\n",
            "✅ Still running...\n",
            "✅ Still running...\n",
            "\u001b[1m31/92\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:16\u001b[0m 2s/step - accuracy: 0.9662 - loss: 0.1211✅ Still running...\n",
            "\u001b[1m86/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.9606 - loss: 0.1335✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9602 - loss: 0.1341✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m601s\u001b[0m 4s/step - accuracy: 0.9602 - loss: 0.1342 - val_accuracy: 0.9577 - val_loss: 0.1671\n",
            "Epoch 7/10\n",
            "✅ Still running...\n",
            "✅ Still running...\n",
            "\u001b[1m32/92\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:11\u001b[0m 2s/step - accuracy: 0.9547 - loss: 0.1343✅ Still running...\n",
            "\u001b[1m87/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.9553 - loss: 0.1345✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9553 - loss: 0.1347✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m598s\u001b[0m 4s/step - accuracy: 0.9553 - loss: 0.1347 - val_accuracy: 0.9604 - val_loss: 0.1485\n",
            "Epoch 8/10\n",
            "✅ Still running...\n",
            "✅ Still running...\n",
            "\u001b[1m22/92\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:39\u001b[0m 2s/step - accuracy: 0.9315 - loss: 0.2032✅ Still running...\n",
            "\u001b[1m78/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.9475 - loss: 0.1627✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9492 - loss: 0.1585✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 4s/step - accuracy: 0.9493 - loss: 0.1583 - val_accuracy: 0.9645 - val_loss: 0.1483\n",
            "Epoch 9/10\n",
            "✅ Still running...\n",
            "✅ Still running...\n",
            "\u001b[1m22/92\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:32\u001b[0m 2s/step - accuracy: 0.9565 - loss: 0.1197✅ Still running...\n",
            "\u001b[1m75/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 0.9604 - loss: 0.1234✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9606 - loss: 0.1237✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m605s\u001b[0m 4s/step - accuracy: 0.9606 - loss: 0.1237 - val_accuracy: 0.9618 - val_loss: 0.1448\n",
            "Epoch 10/10\n",
            "✅ Still running...\n",
            "✅ Still running...\n",
            "\u001b[1m23/92\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:29\u001b[0m 2s/step - accuracy: 0.9516 - loss: 0.1330✅ Still running...\n",
            "\u001b[1m77/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9544 - loss: 0.1306✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9551 - loss: 0.1291✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m596s\u001b[0m 4s/step - accuracy: 0.9551 - loss: 0.1290 - val_accuracy: 0.9618 - val_loss: 0.1359\n",
            "\n",
            "--- Phase 2: Preparing for Fine-Tuning ---\n",
            "\n",
            "--- Phase 2: Starting Fine-Tuning ---\n",
            "Epoch 11/30\n",
            "✅ Still running...\n",
            "✅ Still running...\n",
            "\u001b[1m 7/92\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:14\u001b[0m 3s/step - accuracy: 0.9044 - loss: 0.2606✅ Still running...\n",
            "\u001b[1m46/92\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:21\u001b[0m 3s/step - accuracy: 0.9035 - loss: 0.2437✅ Still running...\n",
            "\u001b[1m81/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m35s\u001b[0m 3s/step - accuracy: 0.9077 - loss: 0.2366✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9088 - loss: 0.2346✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 5s/step - accuracy: 0.9089 - loss: 0.2344 - val_accuracy: 0.9550 - val_loss: 0.1162\n",
            "Epoch 12/30\n",
            "✅ Still running...\n",
            "✅ Still running...\n",
            "\u001b[1m16/92\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:52\u001b[0m 3s/step - accuracy: 0.9369 - loss: 0.1683✅ Still running...\n",
            "\u001b[1m57/92\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:45\u001b[0m 3s/step - accuracy: 0.9376 - loss: 0.1736✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9378 - loss: 0.1726✅ Still running...\n",
            "✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m668s\u001b[0m 5s/step - accuracy: 0.9378 - loss: 0.1727 - val_accuracy: 0.9577 - val_loss: 0.1071\n",
            "Epoch 13/30\n",
            "✅ Still running...\n",
            "✅ Still running...\n",
            "\u001b[1m29/92\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:14\u001b[0m 3s/step - accuracy: 0.9485 - loss: 0.1463✅ Still running...\n",
            "\u001b[1m68/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:13\u001b[0m 3s/step - accuracy: 0.9485 - loss: 0.1472✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9484 - loss: 0.1471✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m694s\u001b[0m 5s/step - accuracy: 0.9484 - loss: 0.1471 - val_accuracy: 0.9523 - val_loss: 0.1072\n",
            "Epoch 14/30\n",
            "✅ Still running...\n",
            "✅ Still running...\n",
            "\u001b[1m 5/92\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:13\u001b[0m 3s/step - accuracy: 0.9690 - loss: 0.1116✅ Still running...\n",
            "\u001b[1m44/92\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:25\u001b[0m 3s/step - accuracy: 0.9529 - loss: 0.1486✅ Still running...\n",
            "\u001b[1m82/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m31s\u001b[0m 3s/step - accuracy: 0.9509 - loss: 0.1487✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9507 - loss: 0.1484✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m676s\u001b[0m 5s/step - accuracy: 0.9507 - loss: 0.1483 - val_accuracy: 0.9563 - val_loss: 0.1056\n",
            "Epoch 15/30\n",
            "✅ Still running...\n",
            "✅ Still running...\n",
            "\u001b[1m15/92\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:53\u001b[0m 3s/step - accuracy: 0.9498 - loss: 0.1532✅ Still running...\n",
            "\u001b[1m52/92\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 3s/step - accuracy: 0.9459 - loss: 0.1533✅ Still running...\n",
            "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 0.9479 - loss: 0.1494✅ Still running...\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9480 - loss: 0.1492"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell to Resume Training from a Checkpoint\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# --- 1. DEFINE PATHS AND CALLBACKS ---\n",
        "SAVE_PATH = '/content/drive/MyDrive/binary_model_checkpoint.keras'\n",
        "\n",
        "# Define the callbacks again\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    SAVE_PATH, save_best_only=True\n",
        ")\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=5, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# --- 2. LOAD YOUR BEST SAVED MODEL ---\n",
        "print(f\"Loading best model from: {SAVE_PATH}\")\n",
        "model = keras.models.load_model(SAVE_PATH)\n",
        "\n",
        "# --- 3. RE-COMPILE FOR FINE-TUNING ---\n",
        "# We re-compile to ensure the optimizer is set correctly\n",
        "print(\"Compiling model for fine-tuning...\")\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-5), # Use the low fine-tuning learning rate\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# --- 4. RESUME FINE-TUNING ---\n",
        "print(\"\\n--- Resuming Fine-Tuning from Epoch 13 ---\")\n",
        "\n",
        "# We set initial_epoch to 13 to continue the count\n",
        "history_resume = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    initial_epoch=13, # Start counting from where you left off\n",
        "    epochs=30, # Keep the original target\n",
        "    callbacks=[early_stopping, checkpoint_cb],\n",
        "    class_weight=class_weight_dict\n",
        ")\n",
        "\n",
        "print(\"\\n🎉 Model fine-tuning complete!\")\n",
        "\n",
        "# --- 5. VISUALIZE RESULTS ---\n",
        "# Note: This will only show the history from the resumed session.\n",
        "# To get the full graph, you would need to combine the old and new history.\n",
        "print(\"Plotting results from the resumed session...\")\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_resume.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history_resume.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Resumed Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_resume.history['loss'], label='Training Loss')\n",
        "plt.plot(history_resume.history['val_loss'], label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Resumed Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfHIeu1gVfLW",
        "outputId": "debeaa28-17b2-4efe-a92f-4adf779e4769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading best model from: /content/drive/MyDrive/binary_model_checkpoint.keras\n",
            "Compiling model for fine-tuning...\n",
            "\n",
            "--- Resuming Fine-Tuning from Epoch 13 ---\n",
            "Epoch 14/30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell to Evaluate the Final Model\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# --- 1. LOAD YOUR BEST SAVED MODEL ---\n",
        "SAVE_PATH = '/content/drive/MyDrive/binary_model_checkpoint.keras'\n",
        "print(f\"Loading best model from: {SAVE_PATH}\")\n",
        "model = tf.keras.models.load_model(SAVE_PATH)\n",
        "\n",
        "# --- 2. MAKE PREDICTIONS ON THE VALIDATION SET ---\n",
        "# The val_ds dataset must be defined by re-running your data prep cell first.\n",
        "print(\"Making predictions on the validation set...\")\n",
        "y_true = np.concatenate([y for x, y in val_ds], axis=0)\n",
        "y_pred_proba = model.predict(val_ds)\n",
        "y_pred = (y_pred_proba > 0.5).astype(\"int32\").flatten()\n",
        "\n",
        "# --- 3. PRINT THE CLASSIFICATION REPORT ---\n",
        "# This gives you precision, recall, and f1-score.\n",
        "print(\"\\n--- Classification Report ---\")\n",
        "target_names = ['No DR', 'DR Present']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))\n",
        "\n",
        "# --- 4. VISUALIZE THE CONFUSION MATRIX ---\n",
        "# This shows you exactly what kind of mistakes the model is making.\n",
        "print(\"\\n--- Confusion Matrix ---\")\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('Actual Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "vhW4ExQwA-cK",
        "outputId": "c1922f46-3b28-4b18-bf96-118107811056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading best model from: /content/drive/MyDrive/binary_model_checkpoint.keras\n",
            "Making predictions on the validation set...\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 4s/step\n",
            "\n",
            "--- Classification Report ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       No DR       0.98      0.96      0.97       361\n",
            "  DR Present       0.96      0.98      0.97       372\n",
            "\n",
            "    accuracy                           0.97       733\n",
            "   macro avg       0.97      0.97      0.97       733\n",
            "weighted avg       0.97      0.97      0.97       733\n",
            "\n",
            "\n",
            "--- Confusion Matrix ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAIjCAYAAABvUIGpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVh5JREFUeJzt3XmcTvX///HnNdtlzJgZg1lkb4SxFj4M2fcQUVHKkKWEZEvjk20qExWlQn2SLVQKRVGWEIaQnWRNYuxmrMPMnN8ffq5vl0NmmGvOjOtx73ZuN9f7vM/7vM71ufn06vV+n/dlMwzDEAAAAPAPHlYHAAAAgOyHJBEAAAAmJIkAAAAwIUkEAACACUkiAAAATEgSAQAAYEKSCAAAABOSRAAAAJiQJAIAAMCEJBHAv9qzZ48aN26swMBA2Ww2zZs3L1PHP3jwoGw2m6ZMmZKp4+ZkdevWVd26da0OA4CbI0kEcoB9+/bp+eefV4kSJZQrVy4FBASoZs2aev/993Xp0iWX3js6Olrbtm3Tm2++qenTp6tKlSouvV9W6tSpk2w2mwICAm76Pe7Zs0c2m002m03vvPNOhsc/cuSIhg8frs2bN2dCtACQtbysDgDAv/v+++/1xBNPyG63q2PHjipXrpyuXLmiVatWaeDAgdqxY4c++eQTl9z70qVLio+P13//+1/16tXLJfcoWrSoLl26JG9vb5eMfzteXl66ePGi5s+fryeffNLp3IwZM5QrVy5dvnz5jsY+cuSIRowYoWLFiqlSpUrpvu6nn366o/sBQGYiSQSysQMHDqh9+/YqWrSoli1bpvDwcMe5nj17au/evfr+++9ddv8TJ05IkoKCglx2D5vNply5crls/Nux2+2qWbOmZs2aZUoSZ86cqebNm+ubb77JklguXryo3Llzy8fHJ0vuBwD/hulmIBsbPXq0zp8/r0mTJjkliNdFRESoT58+js8pKSl6/fXXdf/998tut6tYsWIaPHiwkpOTna4rVqyYWrRooVWrVuk///mPcuXKpRIlSmjatGmOPsOHD1fRokUlSQMHDpTNZlOxYsUkXZumvf7nfxo+fLhsNptT2+LFi/Xwww8rKChI/v7+KlWqlAYPHuw4f6s1icuWLVOtWrXk5+enoKAgtWrVSrt27brp/fbu3atOnTopKChIgYGB6ty5sy5evHjrL/YGTz/9tBYuXKizZ8862tavX689e/bo6aefNvU/ffq0BgwYoPLly8vf318BAQFq1qyZtmzZ4uizfPlyVa1aVZLUuXNnx7T19eesW7euypUrp40bN6p27drKnTu343u5cU1idHS0cuXKZXr+Jk2aKG/evDpy5Ei6nxUA0oskEcjG5s+frxIlSqhGjRrp6t+1a1cNHTpUDz30kMaOHas6deooLi5O7du3N/Xdu3evHn/8cTVq1Ejvvvuu8ubNq06dOmnHjh2SpDZt2mjs2LGSpKeeekrTp0/Xe++9l6H4d+zYoRYtWig5OVmxsbF699139eijj2r16tX/et2SJUvUpEkTHT9+XMOHD1e/fv20Zs0a1axZUwcPHjT1f/LJJ3Xu3DnFxcXpySef1JQpUzRixIh0x9mmTRvZbDbNmTPH0TZz5kyVLl1aDz30kKn//v37NW/ePLVo0UJjxozRwIEDtW3bNtWpU8eRsJUpU0axsbGSpO7du2v69OmaPn26ateu7Rjn1KlTatasmSpVqqT33ntP9erVu2l877//vgoUKKDo6GilpqZKkj7++GP99NNP+uCDD1SwYMF0PysApJsBIFtKTEw0JBmtWrVKV//NmzcbkoyuXbs6tQ8YMMCQZCxbtszRVrRoUUOSsXLlSkfb8ePHDbvdbvTv39/RduDAAUOS8fbbbzuNGR0dbRQtWtQUw7Bhw4x//t/K2LFjDUnGiRMnbhn39XtMnjzZ0VapUiUjJCTEOHXqlKNty5YthoeHh9GxY0fT/Z577jmnMR977DEjX758t7znP5/Dz8/PMAzDePzxx40GDRoYhmEYqampRlhYmDFixIibfgeXL182UlNTTc9ht9uN2NhYR9v69etNz3ZdnTp1DEnGxIkTb3quTp06Tm0//vijIcl44403jP379xv+/v5G69atb/uMAHCnqCQC2VRSUpIkKU+ePOnq/8MPP0iS+vXr59Tev39/STKtXYyMjFStWrUcnwsUKKBSpUpp//79dxzzja6vZfz222+VlpaWrmuOHj2qzZs3q1OnTgoODna0V6hQQY0aNXI85z+98MILTp9r1aqlU6dOOb7D9Hj66ae1fPlyJSQkaNmyZUpISLjpVLN0bR2jh8e1//tMTU3VqVOnHFPpv/32W7rvabfb1blz53T1bdy4sZ5//nnFxsaqTZs2ypUrlz7++ON03wsAMookEcimAgICJEnnzp1LV/8///xTHh4eioiIcGoPCwtTUFCQ/vzzT6f2IkWKmMbImzevzpw5c4cRm7Vr1041a9ZU165dFRoaqvbt2+urr77614TxepylSpUynStTpoxOnjypCxcuOLXf+Cx58+aVpAw9yyOPPKI8efLoyy+/1IwZM1S1alXTd3ldWlqaxo4dq5IlS8putyt//vwqUKCAtm7dqsTExHTf87777svQSyrvvPOOgoODtXnzZo0bN04hISHpvhYAMookEcimAgICVLBgQW3fvj1D19344siteHp63rTdMIw7vsf19XLX+fr6auXKlVqyZImeffZZbd26Ve3atVOjRo1Mfe/G3TzLdXa7XW3atNHUqVM1d+7cW1YRJWnkyJHq16+fateurc8//1w//vijFi9erLJly6a7Yipd+34yYtOmTTp+/Lgkadu2bRm6FgAyiiQRyMZatGihffv2KT4+/rZ9ixYtqrS0NO3Zs8ep/dixYzp79qzjTeXMkDdvXqc3ga+7sVopSR4eHmrQoIHGjBmjnTt36s0339SyZcv0888/33Ts63Hu3r3bdO73339X/vz55efnd3cPcAtPP/20Nm3apHPnzt30ZZ/rvv76a9WrV0+TJk1S+/bt1bhxYzVs2ND0naQ3YU+PCxcuqHPnzoqMjFT37t01evRorV+/PtPGB4AbkSQC2dgrr7wiPz8/de3aVceOHTOd37dvn95//31J16ZLJZneQB4zZowkqXnz5pkW1/3336/ExERt3brV0Xb06FHNnTvXqd/p06dN117fVPrGbXmuCw8PV6VKlTR16lSnpGv79u366aefHM/pCvXq1dPrr7+uDz/8UGFhYbfs5+npaapSzp49W3///bdT2/Vk9mYJdUYNGjRIhw4d0tSpUzVmzBgVK1ZM0dHRt/weAeBusZk2kI3df//9mjlzptq1a6cyZco4/eLKmjVrNHv2bHXq1EmSVLFiRUVHR+uTTz7R2bNnVadOHf3666+aOnWqWrdufcvtVe5E+/btNWjQID322GN66aWXdPHiRU2YMEEPPPCA04sbsbGxWrlypZo3b66iRYvq+PHjGj9+vAoVKqSHH374luO//fbbatasmaKiotSlSxddunRJH3zwgQIDAzV8+PBMe44beXh46LXXXrttvxYtWig2NladO3dWjRo1tG3bNs2YMUMlSpRw6nf//fcrKChIEydOVJ48eeTn56dq1aqpePHiGYpr2bJlGj9+vIYNG+bYkmfy5MmqW7euhgwZotGjR2doPABIF4vfrgaQDn/88YfRrVs3o1ixYoaPj4+RJ08eo2bNmsYHH3xgXL582dHv6tWrxogRI4zixYsb3t7eRuHChY2YmBinPoZxbQuc5s2bm+5z49Yrt9oCxzAM46effjLKlStn+Pj4GKVKlTI+//xz0xY4S5cuNVq1amUULFjQ8PHxMQoWLGg89dRTxh9//GG6x43bxCxZssSoWbOm4evrawQEBBgtW7Y0du7c6dTn+v1u3GJn8uTJhiTjwIEDt/xODcN5C5xbudUWOP379zfCw8MNX19fo2bNmkZ8fPxNt6759ttvjcjISMPLy8vpOevUqWOULVv2pvf85zhJSUlG0aJFjYceesi4evWqU7++ffsaHh4eRnx8/L8+AwDcCZthZGBlNwAAANwCaxIBAABgQpIIAAAAE5JEAAAAmJAkAgAAwIQkEQAAACYkiQAAADAhSQQAAIDJPfmLK761h1sdAgAXObF4mNUhAHARf3vm/d55Rvk+2MtlY1/a9KHLxnYlKokAAAAwuScriQAAABlio252I5JEAAAAm3VT3dkVaTMAAABMqCQCAAAw3WzCNwIAAAATKokAAACsSTShkggAAAATKokAAACsSTThGwEAAIAJlUQAAADWJJqQJAIAADDdbMI3AgAAABMqiQAAAEw3m1BJBAAAyCYmTJigChUqKCAgQAEBAYqKitLChQsd5+vWrSubzeZ0vPDCC05jHDp0SM2bN1fu3LkVEhKigQMHKiUlJcOxUEkEAADIJmsSCxUqpLfeekslS5aUYRiaOnWqWrVqpU2bNqls2bKSpG7duik2NtZxTe7cuR1/Tk1NVfPmzRUWFqY1a9bo6NGj6tixo7y9vTVy5MgMxUKSCAAAkE20bNnS6fObb76pCRMmaO3atY4kMXfu3AoLC7vp9T/99JN27typJUuWKDQ0VJUqVdLrr7+uQYMGafjw4fLx8Ul3LNkjbQYAALCSzeayIzk5WUlJSU5HcnLybUNKTU3VF198oQsXLigqKsrRPmPGDOXPn1/lypVTTEyMLl686DgXHx+v8uXLKzQ01NHWpEkTJSUlaceOHRn6SkgSAQAAXCguLk6BgYFOR1xc3C37b9u2Tf7+/rLb7XrhhRc0d+5cRUZGSpKefvppff755/r5558VExOj6dOn65lnnnFcm5CQ4JQgSnJ8TkhIyFDcTDcDAAC4cE1iTEyM+vXr59Rmt9tv2b9UqVLavHmzEhMT9fXXXys6OlorVqxQZGSkunfv7uhXvnx5hYeHq0GDBtq3b5/uv//+TI2bJBEAAMCFW+DY7fZ/TQpv5OPjo4iICElS5cqVtX79er3//vv6+OOPTX2rVasmSdq7d6/uv/9+hYWF6ddff3Xqc+zYMUm65TrGW2G6GQAAIBtLS0u75RrGzZs3S5LCw8MlSVFRUdq2bZuOHz/u6LN48WIFBAQ4pqzTi0oiAABANtkCJyYmRs2aNVORIkV07tw5zZw5U8uXL9ePP/6offv2aebMmXrkkUeUL18+bd26VX379lXt2rVVoUIFSVLjxo0VGRmpZ599VqNHj1ZCQoJee+019ezZM0PVTIkkEQAAINs4fvy4OnbsqKNHjyowMFAVKlTQjz/+qEaNGumvv/7SkiVL9N577+nChQsqXLiw2rZtq9dee81xvaenpxYsWKAePXooKipKfn5+io6OdtpXMb1shmEYmflw2YFv7eFWhwDARU4sHmZ1CABcxN9u3U/j+dbJeBKVXpdWDHXZ2K6UPWqrAAAAyFaYbgYAAPCwroqZXVFJBAAAgAmVRAAAgGzydnN2QpIIAADgws20cyrSZgAAAJhQSQQAAGC62YRvBAAAACZUEgEAAFiTaEIlEQAAACZUEgEAAFiTaMI3AgAAABMqiQAAAKxJNCFJBAAAYLrZhG8EAAAAJlQSAQAAmG42oZIIAAAAEyqJAAAArEk04RsBAACACZVEAAAA1iSaUEkEAACACZVEAAAA1iSakCQCAACQJJrwjQAAAMCESiIAAAAvrphQSQQAAIAJlUQAAADWJJrwjQAAAMCESiIAAABrEk2oJAIAAMCESiIAAABrEk1IEgEAAJhuNiFtBgAAgAmVRAAA4PZsVBJNqCQCAADAhEoiAABwe1QSzagkAgAAwIRKIgAAAIVEEyqJAAAAMKGSCAAA3B5rEs1IEgEAgNsjSTRjuhkAAAAmVBIBAIDbo5JoRiURAAAAJlQSAQCA26OSaEYlEQAAACZUEgEAACgkmlBJBAAAgAmVRAAA4PZYk2hGJREAAAAmVBIBAIDbo5JoRpIIAADcHkmiGdPNAAAAMKGSCAAA3B6VRDMqiQAAANnEhAkTVKFCBQUEBCggIEBRUVFauHCh4/zly5fVs2dP5cuXT/7+/mrbtq2OHTvmNMahQ4fUvHlz5c6dWyEhIRo4cKBSUlIyHAtJIgAAgM2FRwYUKlRIb731ljZu3KgNGzaofv36atWqlXbs2CFJ6tu3r+bPn6/Zs2drxYoVOnLkiNq0aeO4PjU1Vc2bN9eVK1e0Zs0aTZ06VVOmTNHQoUMz/pUYhmFk+Kpszrf2cKtDAOAiJxYPszoEAC7ib7duyjdf9CyXjX1q6lN3dX1wcLDefvttPf744ypQoIBmzpypxx9/XJL0+++/q0yZMoqPj1f16tW1cOFCtWjRQkeOHFFoaKgkaeLEiRo0aJBOnDghHx+fdN+XSiIAAHB7NpvNZUdycrKSkpKcjuTk5NvGlJqaqi+++EIXLlxQVFSUNm7cqKtXr6phw4aOPqVLl1aRIkUUHx8vSYqPj1f58uUdCaIkNWnSRElJSY5qZHqRJAIAALhQXFycAgMDnY64uLhb9t+2bZv8/f1lt9v1wgsvaO7cuYqMjFRCQoJ8fHwUFBTk1D80NFQJCQmSpISEBKcE8fr56+cygrebAQCA23Pl280xMTHq16+fU5vdbr9l/1KlSmnz5s1KTEzU119/rejoaK1YscJl8d0KSSIAAHB7rkwS7Xb7vyaFN/Lx8VFERIQkqXLlylq/fr3ef/99tWvXTleuXNHZs2edqonHjh1TWFiYJCksLEy//vqr03jX336+3ie9mG4GAADIxtLS0pScnKzKlSvL29tbS5cudZzbvXu3Dh06pKioKElSVFSUtm3bpuPHjzv6LF68WAEBAYqMjMzQfakkAgAAZJO9tGNiYtSsWTMVKVJE586d08yZM7V8+XL9+OOPCgwMVJcuXdSvXz8FBwcrICBAvXv3VlRUlKpXry5Jaty4sSIjI/Xss89q9OjRSkhI0GuvvaaePXtmqJopkSQCAABkG8ePH1fHjh119OhRBQYGqkKFCvrxxx/VqFEjSdLYsWPl4eGhtm3bKjk5WU2aNNH48eMd13t6emrBggXq0aOHoqKi5Ofnp+joaMXGxmY4FvZJBJCjsE8icO+ycp/E0K6zXTb2sU+fcNnYrsSaRAAAAJgw3QwAANyeK99uzqmoJAIAAMCESiIAAHB7VBLNsnWSeOnSJfn6+lodBgAAuMeRJJply+nm5ORkvfvuuypevLjVoQAAALgly5LE5ORkxcTEqEqVKqpRo4bmzZsnSZo8ebKKFy+u9957T3379rUqPAAA4E5sLjxyKMumm4cOHaqPP/5YDRs21Jo1a/TEE0+oc+fOWrt2rcaMGaMnnnhCnp6eVoUHAADg1ixLEmfPnq1p06bp0Ucf1fbt21WhQgWlpKRoy5YtrAsAAABZitzDzLLp5sOHD6ty5cqSpHLlyslut6tv3778jwQAAJANWFZJTE1NlY+Pz/8F4uUlf39/q8IBAABujCKVmWVJomEY6tSpk+x2uyTp8uXLeuGFF+Tn5+fUb86cOVaEBwAA4NYsSxKjo6OdPj/zzDMWRQIAANwdlUQzy5LEyZMnW3VrAAAAZ+SIJtliM23DMHTy5EmdOnXK6lAAAAAgi5PEhIQEdezYUXnz5lVoaKhCQkKUN29ePffcczp27JiVoQEAADdis9lcduRUlk03JyUlqUaNGjp//rw6d+6s0qVLyzAM7dy5U7NmzdKqVav022+/8cYzAACABSxLEt9//315enpqx44dKlCggNO51157TTVr1tS4ceM0ePBgiyIEAADuIidX/FzFsunm77//XoMHDzYliJIUEhKimJgYzZ8/34LIAAAAYFmS+Mcff6hGjRq3PF+jRg3t3r07CyNCdtGtVRX9OrmHji2M0bGFMVo+vosaV4u4ad95ozvo0srhavlwadO5Z5pW0q+Te+jM4tf057cDNbbvIy6OHMCd+G3Der3c6wU1aVBLlSuU1s/LljidH/baq6pcobTT0euFrhZFi3sVaxLNLF2TGBQUdMvzQUFBSkpKyrqAkG38fSJJQz5eor2HT8kmm55pWlGzRz6l6l0matfBE45+vZ+oLuMWY7z0ZJT6tIvS4AmL9evOw/LL5aOi4UFZEj+AjLl06ZIeKFVajz7WVgP79r5pnxo1a2nY6yMdn//5i10AXMPSX1zx8Lh1IdNms8kwbpUC4F72w5o/nD4P/3SZurWuqv+ULeRIEitEhKlPuxqq2f0THZw3wKl/kH8uDetaX21fnanlvx1wtG/fzxvzQHZUs1Zt1axV+1/7ePv4KH9+8/IkILPk5Iqfq1iaJD7wwAO3/B+FBBGS5OFhU9u6ZeWXy1vrth+WJPnavTVlaFu9/N73Onb6vOmaBlXvl4fNpoIFArRpek/l8bVr7fa/9Or4H3X4ONVpICfauOFXNaxTQwEBAaryn+p6sXcfBQXltTos3EvIEU1y/C+uJCcnKzk52anNSEuRzcOyR0MmKFsiRMvHd1UuHy+dv3RF7V77Ur//ea2KOLp3E63d/pcWrLr5mtXiBfPKw8OmV56ppQHjFirpQrKGda2vBe92VNXOE3Q1JTUrHwXAXapRs5bqN2isgvfdp8OH/9JH48bqpRe7a/L0L+Tp6Wl1eMA9K9v8dvOdiouL04gRI5zaPIvUkXfRupkyPqzxx6FTqtZlogL97HqsbqT+N7i1GveeovsLBavuQ8VVvcvHt7zWZrPJx9tT/cct1NL1+yRJ0SO+1sF5A1TnwWJa8v/bAOQMTZo1d/y55AOlVPKBUmr1SCNtXP+r/lM9ysLIcC9hutksx5fbYmJi1K9fP6e2kEdGWxQNMsvVlFTt//u0JGnTH0dVufR96vlENV1OTlGJgsFK+P5Vp/6zXn9Sq7ceUpM+U5Rw6pwk6fd/vORyMvGiTiZeVOHQwKx7CAAuUahQYQXlzau//vqTJBFwoRyfJNrtdtntdqc2pprvPR4eNtm9vfTGZ8s1ecFvTuc2Tn1Rr3z4o75fc236OX7bX5KkkoXz6e8T19Yg5s3jq/yBuXXoWGLWBg4g0x1LSFDi2bPKnz/E6lBwD6GSaEY2hWwntnsD/bhur/46lqg8uX3UrmF51a5UTC0HTNex0+dv+rLKX8cS9efRs5KkvYdPaf4vv+udl5qp1zvzlXQhWbHdG2j3oZNa8Y+3nQFkDxcvXtBfhw45Ph/5+7B2/75LAYGBCgwM1CcTPlKDho2VL39+Hf7rL70/9m0VLlJEUTUftjBq4N5Hkohsp0BeP00a/JjC8vkr8UKytu87ppYDpmvZhv3pHqPLm3M1uncTzRn1tNLSDK3a8qdaDfxcKalpLowcwJ3YuWO7nu/yf+vUx7z9liSpxaOtFfPacO3Zs1sLvpunc+fOqUBIAVWPqqkevfqwVyIyFYVEM5uRjfaauR7K3ZZ8fWsPz4RoAGRHJxYPszoEAC7ib7cuU4sYsNBlY+99p5nLxnYly36W75+mTZum8uXLy9fXV76+vqpQoYKmT59udVgAAMBN8LN8ZpZPN48ZM0ZDhgxRr169VLNmTUnSqlWr9MILL+jkyZPq27evxRECAIB7XQ7O5VzG8iTxgw8+0IQJE9SxY0dH26OPPqqyZctq+PDhJIkAAAAWsDxJPHr0qGrUqGFqr1Gjho4ePWpBRAAAwN3k5GlhV7F8TWJERIS++uorU/uXX36pkiVLWhARAAAALK8kjhgxQu3atdPKlSsdaxJXr16tpUuX3jR5BAAAyGwUEs0sryS2bdtW69atU/78+TVv3jzNmzdP+fPn16+//qrHHnvM6vAAAADckuWVREmqXLmyPv/8c6vDAAAAbsrDg1LijSyvJAIAACD7sayS6OHhcds3iWw2m1JSUrIoIgAA4K5Yk2hmWZI4d+7cW56Lj4/XuHHjlJbG7+wCAADXYwscM8uSxFatWpnadu/erVdffVXz589Xhw4dFBsba0FkAAAAyBZrEo8cOaJu3bqpfPnySklJ0ebNmzV16lQVLVrU6tAAAIAbsNlcd+RUliaJiYmJGjRokCIiIrRjxw4tXbpU8+fPV7ly5awMCwAAwO1ZNt08evRojRo1SmFhYZo1a9ZNp58BAACyAmsSzSxLEl999VX5+voqIiJCU6dO1dSpU2/ab86cOVkcGQAAACxLEjt27EjWDgAAsgVyEjPLksQpU6ZYdWsAAADcRrb4WT4AAAArUUg0I0kEAABuj+lms2yxTyIAAACyFyqJAADA7VFINKOSCAAAABOSRAAA4PZsNpvLjoyIi4tT1apVlSdPHoWEhKh169bavXu3U5+6deua7vHCCy849Tl06JCaN2+u3LlzKyQkRAMHDlRKSkqGYmG6GQAAIJtYsWKFevbsqapVqyolJUWDBw9W48aNtXPnTvn5+Tn6devWTbGxsY7PuXPndvw5NTVVzZs3V1hYmNasWaOjR4+qY8eO8vb21siRI9MdC0kiAABwe9llTeKiRYucPk+ZMkUhISHauHGjateu7WjPnTu3wsLCbjrGTz/9pJ07d2rJkiUKDQ1VpUqV9Prrr2vQoEEaPny4fHx80hUL080AAAAulJycrKSkJKcjOTk5XdcmJiZKkoKDg53aZ8yYofz586tcuXKKiYnRxYsXHefi4+NVvnx5hYaGOtqaNGmipKQk7dixI91xkyQCAAC358o1iXFxcQoMDHQ64uLibhtTWlqaXn75ZdWsWVPlypVztD/99NP6/PPP9fPPPysmJkbTp0/XM8884zifkJDglCBKcnxOSEhI93fCdDMAAIALxcTEqF+/fk5tdrv9ttf17NlT27dv16pVq5zau3fv7vhz+fLlFR4ergYNGmjfvn26//77MydokSQCAAC4dE2i3W5PV1L4T7169dKCBQu0cuVKFSpU6F/7VqtWTZK0d+9e3X///QoLC9Ovv/7q1OfYsWOSdMt1jDfDdDMAAHB72WULHMMw1KtXL82dO1fLli1T8eLFb3vN5s2bJUnh4eGSpKioKG3btk3Hjx939Fm8eLECAgIUGRmZ7lioJAIAAGQTPXv21MyZM/Xtt98qT548jjWEgYGB8vX11b59+zRz5kw98sgjypcvn7Zu3aq+ffuqdu3aqlChgiSpcePGioyM1LPPPqvRo0crISFBr732mnr27JmhiiZJIgAAcHvZZQucCRMmSLq2YfY/TZ48WZ06dZKPj4+WLFmi9957TxcuXFDhwoXVtm1bvfbaa46+np6eWrBggXr06KGoqCj5+fkpOjraaV/F9CBJBAAAyCYMw/jX84ULF9aKFStuO07RokX1ww8/3FUsJIkAAMDtZXTtoDvgxRUAAACYUEkEAABuj0KiGZVEAAAAmFBJBAAAbo81iWYkiQAAwO2RI5ox3QwAAAATKokAAMDtMd1sRiURAAAAJlQSAQCA26OSaEYlEQAAACZUEgEAgNujkGhGJREAAAAmVBIBAIDbY02iGUkiAABwe+SIZkw3AwAAwIRKIgAAcHtMN5tRSQQAAIAJlUQAAOD2KCSaUUkEAACACZVEAADg9jwoJZpQSQQAAIAJlUQAAOD2KCSakSQCAAC3xxY4Zkw3AwAAwIRKIgAAcHseFBJNqCQCAADAhEoiAABwe6xJNKOSCAAAABMqiQAAwO1RSDSjkggAAAATKokAAMDt2UQp8UYkiQAAwO2xBY4Z080AAAAwoZIIAADcHlvgmKUrSfzuu+/SPeCjjz56x8EAAAAge0hXkti6det0DWaz2ZSamno38QAAAGQ5Colm6UoS09LSXB0HAAAAspG7WpN4+fJl5cqVK7NiAQAAsIQHpUSTDL/dnJqaqtdff1333Xef/P39tX//fknSkCFDNGnSpEwPEAAAAFkvw0nim2++qSlTpmj06NHy8fFxtJcrV06ffvpppgYHAACQFWw21x05VYaTxGnTpumTTz5Rhw4d5Onp6WivWLGifv/990wNDgAAICvYbDaXHTlVhpPEv//+WxEREab2tLQ0Xb16NVOCAgAAgLUynCRGRkbql19+MbV//fXXevDBBzMlKAAAgKzEdLNZht9uHjp0qKKjo/X3338rLS1Nc+bM0e7duzVt2jQtWLDAFTECAAAgi2W4ktiqVSvNnz9fS5YskZ+fn4YOHapdu3Zp/vz5atSokStiBAAAcCkPm81lR051R/sk1qpVS4sXL87sWAAAAJBN3PFm2hs2bNCuXbskXVunWLly5UwLCgAAICvl3Hqf62Q4STx8+LCeeuoprV69WkFBQZKks2fPqkaNGvriiy9UqFChzI4RAAAAWSzDaxK7du2qq1evateuXTp9+rROnz6tXbt2KS0tTV27dnVFjAAAAC7FPolmGa4krlixQmvWrFGpUqUcbaVKldIHH3ygWrVqZWpwAAAAWcEj5+ZyLpPhSmLhwoVvuml2amqqChYsmClBAQAAwFoZThLffvtt9e7dWxs2bHC0bdiwQX369NE777yTqcEBAABkBaabzdI13Zw3b16nh7xw4YKqVasmL69rl6ekpMjLy0vPPfecWrdu7ZJAAQAAkHXSlSS+9957Lg4DAADAOtml4BcXF6c5c+bo999/l6+vr2rUqKFRo0Y5vQty+fJl9e/fX1988YWSk5PVpEkTjR8/XqGhoY4+hw4dUo8ePfTzzz/L399f0dHRiouLcxT40iNdPaOjozPweAAAALgTK1asUM+ePVW1alWlpKRo8ODBaty4sXbu3Ck/Pz9JUt++ffX9999r9uzZCgwMVK9evdSmTRutXr1a0rX3RJo3b66wsDCtWbNGR48eVceOHeXt7a2RI0emOxabYRjGnT7I5cuXdeXKFae2gICAOx0u0/jWHm51CABc5MTiYVaHAMBF/O3WlfM6ztzqsrGnPV3hjq89ceKEQkJCtGLFCtWuXVuJiYkqUKCAZs6cqccff1yS9Pvvv6tMmTKKj49X9erVtXDhQrVo0UJHjhxxVBcnTpyoQYMG6cSJE/Lx8UnXvTP84sqFCxfUq1cvhYSEyM/PT3nz5nU6AAAA8H+Sk5OVlJTkdCQnJ6fr2sTERElScHCwJGnjxo26evWqGjZs6OhTunRpFSlSRPHx8ZKk+Ph4lS9f3mn6uUmTJkpKStKOHTvSHXeGk8RXXnlFy5Yt04QJE2S32/Xpp59qxIgRKliwoKZNm5bR4QAAACznYXPdERcXp8DAQKcjLi7utjGlpaXp5ZdfVs2aNVWuXDlJUkJCgnx8fBy/enddaGioEhISHH3+mSBeP3/9XHpleDPt+fPna9q0aapbt646d+6sWrVqKSIiQkWLFtWMGTPUoUOHjA4JAABgKVduVRMTE6N+/fo5tdnt9tte17NnT23fvl2rVq1yVWj/KsOVxNOnT6tEiRKSrq0/PH36tCTp4Ycf1sqVKzM3OgAAgBzObrcrICDA6bhdktirVy8tWLBAP//8swoVKuRoDwsL05UrV3T27Fmn/seOHVNYWJijz7Fjx0znr59LrwwniSVKlNCBAwckXZsD/+qrryRdqzDeWPoEAADICWwuPDLCMAz16tVLc+fO1bJly1S8eHGn85UrV5a3t7eWLl3qaNu9e7cOHTqkqKgoSVJUVJS2bdum48ePO/osXrxYAQEBioyMTHcsGZ5u7ty5s7Zs2aI6dero1VdfVcuWLfXhhx/q6tWrGjNmTEaHAwAAwP/Xs2dPzZw5U99++63y5MnjWEMYGBgoX19fBQYGqkuXLurXr5+Cg4MVEBCg3r17KyoqStWrV5ckNW7cWJGRkXr22Wc1evRoJSQk6LXXXlPPnj3TNc193V1tgSNJf/75pzZu3KiIiAhVqHDnr3hnJrbAAe5dbIED3Lus3AKn65fbXTb2p+3KpbvvrdZGTp48WZ06dZL0f5tpz5o1y2kz7X9OJf/555/q0aOHli9fLj8/P0VHR+utt97K0Gbad50kXnf48GHFxsbqk08+yYzh7gpJInDvIkkE7l0kidlLhtck3sqpU6c0adKkzBoOAAAgy9hsrjtyqkxLEgEAAHDvyPCLKwAAAPcaV+6TmFNRSQQAAIBJuiuJbdq0+dfzN27qCAAAkFNQSDRLd5IYGBh42/MdO3a864AAAACymgdZokm6k8TJkye7Mg4AAABkI7y4AgAA3B6FRDNeXAEAAIAJlUQAAOD22ALHjEoiAAAATO7JSuKZZcOtDgGAi+St2svqEAC4yKVNH1p2b6pmZulKEr/77rt0D/joo4/ecTAAAADIHtKVJLZu3Tpdg9lsNqWmpt5NPAAAAFmONYlm6UoS09LSXB0HAACAZTzIEU2YggcAAIDJHb24cuHCBa1YsUKHDh3SlStXnM699NJLmRIYAABAVqGSaJbhJHHTpk165JFHdPHiRV24cEHBwcE6efKkcufOrZCQEJJEAACAe0CGp5v79u2rli1b6syZM/L19dXatWv1559/qnLlynrnnXdcESMAAIBL2Ww2lx05VYaTxM2bN6t///7y8PCQp6enkpOTVbhwYY0ePVqDBw92RYwAAADIYhlOEr29veXhce2ykJAQHTp0SJIUGBiov/76K3OjAwAAyAIeNtcdOVWG1yQ++OCDWr9+vUqWLKk6depo6NChOnnypKZPn65y5cq5IkYAAABksQxXEkeOHKnw8HBJ0ptvvqm8efOqR48eOnHihD755JNMDxAAAMDVbDbXHTlVhiuJVapUcfw5JCREixYtytSAAAAAsppHTs7mXITNtAEAAGCS4Upi8eLF//V17v37999VQAAAAFmNqplZhpPEl19+2enz1atXtWnTJi1atEgDBw7MrLgAAABgoQwniX369Llp+0cffaQNGzbcdUAAAABZjSWJZplWXW3WrJm++eabzBoOAAAAFspwJfFWvv76awUHB2fWcAAAAFmGt5vN7mgz7X++uGIYhhISEnTixAmNHz8+U4MDAACANTKcJLZq1copSfTw8FCBAgVUt25dlS5dOlODAwAAyAoUEs0ynCQOHz7cBWEAAABYJyf/xrKrZPjFFU9PTx0/ftzUfurUKXl6emZKUAAAALBWhiuJhmHctD05OVk+Pj53HRAAAEBW48UVs3QniePGjZMk2Ww2ffrpp/L393ecS01N1cqVK1mTCAAAcI9Id5I4duxYSdcqiRMnTnSaWvbx8VGxYsU0ceLEzI8QAADAxSgkmqU7STxw4IAkqV69epozZ47y5s3rsqAAAABgrQyvSfz5559dEQcAAIBleLvZLMNvN7dt21ajRo0ytY8ePVpPPPFEpgQFAAAAa2U4SVy5cqUeeeQRU3uzZs20cuXKTAkKAAAgK9lc+E9OleHp5vPnz990qxtvb28lJSVlSlAAAABZielmswxXEsuXL68vv/zS1P7FF18oMjIyU4ICAACAtTJcSRwyZIjatGmjffv2qX79+pKkpUuXatasWZo9e3amBwgAAOBqVBLNMpwktmzZUvPmzdPIkSP19ddfy9fXVxUqVNCSJUtUp04dV8QIAACALJbhJFGSmjdvrubNm5vat2/frnLlyt11UAAAAFnJxm7aJhlek3ijc+fO6ZNPPtF//vMfVaxYMTNiAgAAgMXuOElcuXKlOnbsqPDwcL3zzjuqX7++1q5dm5mxAQAAZAkPm+uOnCpD080JCQmaMmWKJk2apKSkJD355JNKTk7WvHnzeLMZAADgHpLuSmLLli1VqlQpbd26Ve+9956OHDmiDz74wJWxAQAAZAmbzXVHTpXuSuLChQv10ksvqUePHipZsqQrYwIAAMhSHjk5m3ORdFcSV61apXPnzqly5cqqVq2aPvzwQ508edKVsQEAAMAi6U4Sq1evrv/97386evSonn/+eX3xxRcqWLCg0tLStHjxYp07d86VcQIAALgML66YZfjtZj8/Pz333HNatWqVtm3bpv79++utt95SSEiIHn30UVfECAAA4DZWrlypli1bqmDBgrLZbJo3b57T+U6dOslmszkdTZs2depz+vRpdejQQQEBAQoKClKXLl10/vz5DMVxV/sklipVSqNHj9bhw4c1a9asuxkKAADAMtnpxZULFy6oYsWK+uijj27Zp2nTpjp69KjjuDEP69Chg3bs2KHFixdrwYIFWrlypbp3756hOO7oF1du5OnpqdatW6t169aZMRwAAIDbatasmZo1a/avfex2u8LCwm56bteuXVq0aJHWr1+vKlWqSJI++OADPfLII3rnnXdUsGDBdMVx17+4AgAAkNN5yOayIzk5WUlJSU5HcnLyXcW7fPlyhYSEqFSpUurRo4dOnTrlOBcfH6+goCBHgihJDRs2lIeHh9atW5eB7wQAAAAuExcXp8DAQKcjLi7ujsdr2rSppk2bpqVLl2rUqFFasWKFmjVrptTUVEnXfvwkJCTE6RovLy8FBwcrISEh3ffJlOlmAACAnMyV2yTGxMSoX79+Tm12u/2Ox2vfvr3jz+XLl1eFChV0//33a/ny5WrQoMEdj3sjkkQAAOD2XLlVjd1uv6uk8HZKlCih/Pnza+/evWrQoIHCwsJ0/Phxpz4pKSk6ffr0Ldcx3gzTzQAAADnY4cOHderUKYWHh0uSoqKidPbsWW3cuNHRZ9myZUpLS1O1atXSPS6VRAAA4Pay08/ynT9/Xnv37nV8PnDggDZv3qzg4GAFBwdrxIgRatu2rcLCwrRv3z698sorioiIUJMmTSRJZcqUUdOmTdWtWzdNnDhRV69eVa9evdS+fft0v9ksUUkEAADIVjZs2KAHH3xQDz74oCSpX79+evDBBzV06FB5enpq69atevTRR/XAAw+oS5cuqly5sn755RenKe0ZM2aodOnSatCggR555BE9/PDD+uSTTzIUh80wDCNTnywbuJxidQQAXCVv1V5WhwDARS5t+tCye/9v3Z8uG7tbtaIuG9uVqCQCAADAhDWJAADA7WWnNYnZBZVEAAAAmFBJBAAAbo9CohlJIgAAcHtMrZrxnQAAAMCESiIAAHB7NuabTagkAgAAwIRKIgAAcHvUEc2oJAIAAMCESiIAAHB7bKZtRiURAAAAJlQSAQCA26OOaEaSCAAA3B6zzWZMNwMAAMCESiIAAHB7bKZtRiURAAAAJlQSAQCA26NqZsZ3AgAAABMqiQAAwO2xJtGMSiIAAABMqCQCAAC3Rx3RjEoiAAAATKgkAgAAt8eaRDOSRAAA4PaYWjWz/DuZNm2akpOTTe1XrlzRtGnTLIgIAAAAlieJnTt3VmJioqn93Llz6ty5swURAQAAd2Oz2Vx25FSWJ4mGYdz0Czx8+LACAwMtiAgAAACWrUl88MEHHRl2gwYN5OX1f6GkpqbqwIEDatq0qVXhAQAAN5Jz632uY1mS2Lp1a0nS5s2b1aRJE/n7+zvO+fj4qFixYmrbtq1F0QEAALg3y5LEYcOGSZKKFSumdu3aKVeuXFaFAgAA3FwOXjroMpZvgRMdHS3p2tvMx48fV1pamtP5IkWKWBEWAACAW7M8SdyzZ4+ee+45rVmzxqn9+gstqampFkUGAADchQerEk0sTxI7deokLy8vLViwQOHh4Tn6VXEAAJAzkX6YWZ4kbt68WRs3blTp0qWtDgUAAAD/n+VJYmRkpE6ePGl1GAAAwI3ZmG42sXwz7VGjRumVV17R8uXLderUKSUlJTkdAAAAyHqWVxIbNmwoSWrQoIFTOy+uAACArMKaRDPLk8Sff/7Z6hAAAABwA8uTxDp16lgdAgAAcHNsgWNm+ZpESfrll1/0zDPPqEaNGvr7778lSdOnT9eqVassjgwAAMA9WZ4kfvPNN2rSpIl8fX3122+/KTk5WZKUmJiokSNHWhwdAABwBzab646cyvIk8Y033tDEiRP1v//9T97e3o72mjVr6rfffrMwMgAA4C5IEs0sTxJ3796t2rVrm9oDAwN19uzZrA8IAAAA1ieJYWFh2rt3r6l91apVKlGihAURAQAAd2Nz4T85leVJYrdu3dSnTx+tW7dONptNR44c0YwZMzRgwAD16NHD6vAAAADckuVb4Lz66qtKS0tTgwYNdPHiRdWuXVt2u10DBgxQ7969rQ4PAAC4AY+cW/BzGZthGIbVQUjSlStXtHfvXp0/f16RkZHy9/e/47Eup2RiYACylbxVe1kdAgAXubTpQ8vuvfT3ky4bu0Hp/C4b25UsryRe5+Pjo8jISCUlJWnJkiUqVaqUypQpY3VYAADADeTktYOuYvmaxCeffFIffnjtvxwuXbqkqlWr6sknn1SFChX0zTffWBwdAACAe7I8SVy5cqVq1aolSZo7d67S0tJ09uxZjRs3Tm+88YbF0QEAAHfAPolmlieJiYmJCg4OliQtWrRIbdu2Ve7cudW8eXPt2bPH4ugAAIA7YAscM8uTxMKFCys+Pl4XLlzQokWL1LhxY0nSmTNnlCtXLoujAwAAcE+Wv7jy8ssvq0OHDvL391eRIkVUt25dSdemocuXL29tcAAAwC2wBY6Z5ZXEF198UfHx8frss8+0evVqeXhcC6lEiRKsSQQAAG5n5cqVatmypQoWLCibzaZ58+Y5nTcMQ0OHDlV4eLh8fX3VsGFD0xK906dPq0OHDgoICFBQUJC6dOmi8+fPZygOy5NESapSpYqaN2+uv//+Wykp1zY5bN68uWrWrGlxZAAAwB1kpzWJFy5cUMWKFfXRRx/d9Pzo0aM1btw4TZw4UevWrZOfn5+aNGmiy5cvO/p06NBBO3bs0OLFi7VgwQKtXLlS3bt3z9h3YvVm2hcvXlTv3r01depUSdIff/yhEiVKqHfv3rrvvvv06quvZnhMNtMG7l1spg3cu6zcTPuXP864bOxaD+S942ttNpvmzp2r1q1bS7pWRSxYsKD69++vAQMGSLr2EnBoaKimTJmi9u3ba9euXYqMjNT69etVpUoVSddeDn7kkUd0+PBhFSxYMF33trySGBMToy1btmj58uVOL6o0bNhQX375pYWRITtr1qi+KpYtZTpGvj7C6tAA/ItuTzysX7+M0bFf3taxX97W8qn91bhmpFOfahWKa+HHvXVyzbs69svbWjzpZeWyezvO//79CF3a9KHTMaBzo6x+FNxjXLkFTnJyspKSkpyO5OTkO4rzwIEDSkhIUMOGDR1tgYGBqlatmuLj4yVJ8fHxCgoKciSI0rW8ysPDQ+vWrUv3vSx/cWXevHn68ssvVb16ddn+sZlQ2bJltW/fPgsjQ3Y248uvlZaa6vi8d+8ePd+1sxo1aWphVABu5+9jZzXkg2+199AJ2WTTMy2rafbY7qre/i3t2p+gahWK69sPX9Q7k39Sv1GzlZKapgoP3Ke0NOdJrxHjF2jynNWOz+cu3Nm/cIGsEBcXpxEjnIsYw4YN0/DhwzM8VkJCgiQpNDTUqT00NNRxLiEhQSEhIU7nvby8FBwc7OiTHpYniSdOnDA9iHRtPt6Wk3eghEtd31vzus8+/USFCxdRlar/sSgiAOnxw8rtTp+HfzRf3Z54WP+pUFy79idodP82Gv/Fcr0zebGjz54/j5vGOX/hso6dOufyeOE+XJlxxMTEqF+/fk5tdrvdhXfMHJZPN1epUkXff/+94/P1xPDTTz9VVFSUVWEhB7l65Yq+X/CdWrdpy39YADmIh4dNTzSpLD9fH63bekAF8vrrPxWK68Tp8/p5Sj8dXDJSP33aRzUqlTBd279zYx3+eZTiZw1S344N5Olp+b/OkMN52GwuO+x2uwICApyOO00Sw8LCJEnHjh1zaj927JjjXFhYmI4fd/6Pq5SUFJ0+fdrRJz0srySOHDlSzZo1086dO5WSkqL3339fO3fu1Jo1a7RixYrbXp+cnGya1zc87TkiQ0fmWLZsic6dO6dHWz9mdSgA0qFsREEtn9pfuXy8dP5Sstr1/59+35+g/5QvJkn67/OPKGbsXG3dfVgdWvxHP3zcW5WfGKl9h05IksbPWqFNu/7SmaQLql6xhGJ7P6qwAoEa9O4cC58KyBrFixdXWFiYli5dqkqVKkmSkpKStG7dOvXo0UOSFBUVpbNnz2rjxo2qXLmyJGnZsmVKS0tTtWrV0n0vy//T6+GHH9aWLVuUkpKi8uXL66efflJISIji4+MdD/Zv4uLiFBgY6HS8PSouCyJHdjH3m29U8+HaCgkJvX1nAJb74+AxVWsfp9od39H/Zq/S/2KfVekSYfL4/7sZT/pmlaZ/t1Zbdh/WK+/O0R8Hjyu61f/NLI37fJl+2bhH2/cc0adfr9KrY+aoR7s68vG2vO6BHMzmwiOjzp8/r82bN2vz5s2Srr2ssnnzZh06dEg2m00vv/yy3njjDX333Xfatm2bOnbsqIIFCzregC5TpoyaNm2qbt266ddff9Xq1avVq1cvtW/fPt1vNksWVxKvXr2q559/XkOGDNH//ve/OxrjZvP8hidVRHdx5MjfWrd2jca8/4HVoQBIp6spqdr/10lJ0qZdf6ly2SLq+VRdxzrEXfudF9bvPpCgwmG33kJk/baD8vb2VNGCwTddvwjkNBs2bFC9evUcn6/nOdHR0ZoyZYpeeeUVXbhwQd27d9fZs2f18MMPa9GiRU67xMyYMUO9evVSgwYN5OHhobZt22rcuHEZisPSJNHb21vffPONhgwZcsdj2O3mqWX2SXQf386do+DgfKpVu67VoQC4Qx42m+w+XvrzyCkdOX5WDxRzfpkxomiIflq985bXVyxVSKmpaTpxmhdZcBey0ZL2unXr6t+2sbbZbIqNjVVsbOwt+wQHB2vmzJl3FYfl082tW7c2/dwMkB5paWn6du4ctWzVWl5eTDMBOUFs70dV86H7VSQ8WGUjCiq296OqXaWkvvhhgyRp7NQlerF9XT3WsJJKFM6voS82V6lioZoy79r+b9UqFFevp+uq/AP3qdh9+dS+WRWNGtBWs35Yr7PnLln5aMA9x/J/s5YsWVKxsbFavXq1KleuLD8/P6fzL730kkWRIbtbG79GR48eUes2ba0OBUA6FQj216TXOyosf4ASz1/W9j1/q+WL47Vs3e+SpA9nLlcuu7dG92+rvIG5te2Pv9Wix4c6cPja9HTylat6okll/feFR2T39tLBI6f0wYyfNW76MisfC/eAO/n5vHud5T/LV7x48Vues9ls2r9/f4bHZLoZuHfxs3zAvcvKn+Vbty/RZWNXuz/QZWO7kuWVxAMHDlgdAgAAcHNss2tmaZK4du1azZ8/X1euXFGDBg3UtCk/qQYAALIeOaKZZUni119/rXbt2snX11fe3t4aM2aMRo0apQEDBlgVEgAAAP4/y95ujouLU7du3ZSYmKgzZ87ojTfe0MiRI60KBwAAuLPstJt2NmFZkrh7924NGDBAnp6ekqT+/fvr3Llzpt8aBAAAQNazLEm8ePGiAgICHJ99fHyUK1cunT9/3qqQAACAm7K58J+cytIXVz799FP5+/s7PqekpGjKlCnKnz+/o419EgEAALKeZfskFitWTLbbvG/OPokAbsQ+icC9y8p9EjceTHLZ2JWLBdy+UzZkWSXx4MGDVt0aAAAAt2H5ZtoAAABWy7krB12HJBEAAIAs0cSyt5sBAACQfVFJBAAAbi8nb1XjKlQSAQAAYJJtk8TffvtNLVq0sDoMAADgBmw21x05laVJ4o8//qgBAwZo8ODBjv0Qf//9d7Vu3VpVq1ZVWlqaleEBAAC4LcvWJE6aNEndunVTcHCwzpw5o08//VRjxoxR79691a5dO23fvl1lypSxKjwAAOBGcnDBz2UsqyS+//77GjVqlE6ePKmvvvpKJ0+e1Pjx47Vt2zZNnDiRBBEAAMBCllUS9+3bpyeeeEKS1KZNG3l5eentt99WoUKFrAoJAAC4K0qJJpYliZcuXVLu3LklXfuNZrvdrvDwcKvCAQAAbowtcMws3Sfx008/lb+/vyQpJSVFU6ZMUf78+Z36vPTSS1aEBgAA4NZshmEYVty4WLFist3mvXCbzeZ46zkjLqfcaVQAsru8VXtZHQIAF7m06UPL7r3t8HmXjV2+kL/LxnYlyyqJBw8etOrWAAAAuA1+lg8AALg9ViSaWZokpqWlacqUKZozZ44OHjwom82m4sWL6/HHH9ezzz572+loAAAAuIZl+yQahqFHH31UXbt21d9//63y5curbNmy+vPPP9WpUyc99thjVoUGAADcjc2FRw5lWSVxypQpWrlypZYuXap69eo5nVu2bJlat26tadOmqWPHjhZFCAAA4L4sqyTOmjVLgwcPNiWIklS/fn29+uqrmjFjhgWRAQAAd2Nz4T85lWVJ4tatW9W0adNbnm/WrJm2bNmShREBAADgOsumm0+fPq3Q0NBbng8NDdWZM2eyMCIAAOCueFfWzLIkMTU1VV5et769p6enUlLYFRsAALgeOaKZZUmiYRjq1KmT7Hb7Tc8nJydncUQAAAC4zrIkMTo6+rZ9eLMZAABkCUqJJpYliZMnT7bq1gAAALgNfpYPAAC4vZy8VY2rWLYFDgAAALIvKokAAMDtsQWOGZVEAAAAmFBJBAAAbo9CohlJIgAAAFmiCdPNAAAAMKGSCAAA3B5b4JhRSQQAAIAJlUQAAOD22ALHjEoiAAAATKgkAgAAt0ch0YxKIgAAAEyoJAIAAFBKNCFJBAAAbo8tcMyYbgYAAIAJSSIAAHB7NpvrjowYPny4bDab01G6dGnH+cuXL6tnz57Kly+f/P391bZtWx07diyTv41rSBIBAACykbJly+ro0aOOY9WqVY5zffv21fz58zV79mytWLFCR44cUZs2bVwSB2sSAQCA28tOKxK9vLwUFhZmak9MTNSkSZM0c+ZM1a9fX5I0efJklSlTRmvXrlX16tUzNQ4qiQAAAC6UnJyspKQkpyM5OfmW/ffs2aOCBQuqRIkS6tChgw4dOiRJ2rhxo65evaqGDRs6+pYuXVpFihRRfHx8psdNkggAAGBz3REXF6fAwECnIy4u7qZhVKtWTVOmTNGiRYs0YcIEHThwQLVq1dK5c+eUkJAgHx8fBQUFOV0TGhqqhISETP06JKabAQAAXComJkb9+vVzarPb7Tft26xZM8efK1SooGrVqqlo0aL66quv5Ovr69I4b0SSCAAA3J4r90m02+23TApvJygoSA888ID27t2rRo0a6cqVKzp79qxTNfHYsWM3XcN4t5huBgAAbi+7bIFzo/Pnz2vfvn0KDw9X5cqV5e3traVLlzrO7969W4cOHVJUVNRdfgNmVBIBAACyiQEDBqhly5YqWrSojhw5omHDhsnT01NPPfWUAgMD1aVLF/Xr10/BwcEKCAhQ7969FRUVlelvNkskiQAAANlmC5zDhw/rqaee0qlTp1SgQAE9/PDDWrt2rQoUKCBJGjt2rDw8PNS2bVslJyerSZMmGj9+vEtisRmGYbhkZAtdTrE6AgCukrdqL6tDAOAilzZ9aNm9/zp96y1p7lbh4Dtbj2g1KokAAMDt3e3awXsRL64AAADAhEoiAABAtlmVmH1QSQQAAIAJlUQAAOD2WJNoRpIIAADcHjmiGdPNAAAAMKGSCAAA3B7TzWZUEgEAAGBCJREAALg9G6sSTagkAgAAwIRKIgAAAIVEEyqJAAAAMKGSCAAA3B6FRDOSRAAA4PbYAseM6WYAAACYUEkEAABujy1wzKgkAgAAwIRKIgAAAIVEEyqJAAAAMKGSCAAA3B6FRDMqiQAAADChkggAANwe+ySakSQCAAC3xxY4Zkw3AwAAwIRKIgAAcHtMN5tRSQQAAIAJSSIAAABMSBIBAABgwppEAADg9liTaEYlEQAAACZUEgEAgNtjn0QzkkQAAOD2mG42Y7oZAAAAJlQSAQCA26OQaEYlEQAAACZUEgEAACglmlBJBAAAgAmVRAAA4PbYAseMSiIAAABMqCQCAAC3xz6JZlQSAQAAYEIlEQAAuD0KiWYkiQAAAGSJJkw3AwAAwIRKIgAAcHtsgWNGJREAAAAmVBIBAIDbYwscMyqJAAAAMLEZhmFYHQRwp5KTkxUXF6eYmBjZ7XarwwGQifj7DViLJBE5WlJSkgIDA5WYmKiAgACrwwGQifj7DViL6WYAAACYkCQCAADAhCQRAAAAJiSJyNHsdruGDRvGonbgHsTfb8BavLgCAAAAEyqJAAAAMCFJBAAAgAlJIgAAAExIEgEAAGBCkogs1alTJ9lsNr311ltO7fPmzZPtLn9dfcqUKbLZbLLZbPL09FTevHlVrVo1xcbGKjEx8aZx2Gw2eXt7q3jx4nrllVd0+fLlu4oByMlu/HsRGhqqRo0a6bPPPlNaWppT32LFijn65s6dW+XLl9enn35623v88zo/Pz899NBDmj17tqseKdMMHz5clSpVsjoMIEuRJCLL5cqVS6NGjdKZM2cyfeyAgAAdPXpUhw8f1po1a9S9e3dNmzZNlSpV0pEjR5z6Nm3aVEePHtX+/fs1duxYffzxxxo2bFimxwTkJNf/Xhw8eFALFy5UvXr11KdPH7Vo0UIpKSlOfWNjY3X06FFt375dzzzzjLp166aFCxfe9h7Xr9u0aZOqVq2qdu3aac2aNTfte+XKlUx5LgAZR5KILNewYUOFhYUpLi7uX/t98803Klu2rOx2u4oVK6Z33333tmPbbDaFhYUpPDxcZcqUUZcuXbRmzRqdP39er7zyilNfu92usLAwFS5cWK1bt1bDhg21ePHiu3o2IKe7/vfivvvu00MPPaTBgwfr22+/1cKFCzVlyhSnvnny5FFYWJhKlCihQYMGKTg4OF1/h65f98ADD+ijjz6Sr6+v5s+fL+lapfH1119Xx44dFRAQoO7du0uSVq1apVq1asnX11eFCxfWSy+9pAsXLjjGHD9+vEqWLKlcuXIpNDRUjz/+uONcWlqa4uLiVLx4cfn6+qpixYr6+uuvHeeXL18um82mpUuXqkqVKsqdO7dq1Kih3bt3S7o2SzFixAht2bLFUQW98bsA7kUkichynp6eGjlypD744AMdPnz4pn02btyoJ598Uu3bt9e2bds0fPhwDRky5I7+jzkkJEQdOnTQd999p9TU1Jv22b59u9asWSMfH58Mjw/c6+rXr6+KFStqzpw5Nz2flpamb775RmfOnMnw3yEvLy95e3s7VQzfeecdVaxYUZs2bdKQIUO0b98+NW3aVG3bttXWrVv15ZdfatWqVerVq5ckacOGDXrppZcUGxur3bt3a9GiRapdu7ZjvLi4OE2bNk0TJ07Ujh071LdvXz3zzDNasWKFUyz//e9/9e6772rDhg3y8vLSc889J0lq166d+vfvr7Jly+ro0aM6evSo2rVrl6HnBHIiL6sDgHt67LHHVKlSJQ0bNkyTJk0ynR8zZowaNGigIUOGSJIeeOAB7dy5U2+//bY6deqU4fuVLl1a586d06lTpxQSEiJJWrBggfz9/ZWSkqLk5GR5eHjoww8/vKvnAu5VpUuX1tatW53aBg0apNdee03JyclKSUlRcHCwunbtmu4xr1y5onfffVeJiYmqX7++o71+/frq37+/43PXrl3VoUMHvfzyy5KkkiVLaty4capTp44mTJigQ4cOyc/PTy1atFCePHlUtGhRPfjgg5Kk5ORkjRw5UkuWLFFUVJQkqUSJElq1apU+/vhj1alTx3GfN9980/H51VdfVfPmzXX58mX5+vrK399fXl5eCgsLy9gXB+RgVBJhmVGjRmnq1KnatWuX6dyuXbtUs2ZNp7aaNWtqz549t6wG/pvrPyz0z5dj6tWrp82bN2vdunWKjo5W586d1bZt2wyPDbgDwzBML5cNHDhQmzdv1rJly1StWjWNHTtWERERtx1r0KBB8vf3V+7cuTVq1Ci99dZbat68ueN8lSpVnPpv2bJFU6ZMkb+/v+No0qSJ0tLSdODAATVq1EhFixZViRIl9Oyzz2rGjBm6ePGiJGnv3r26ePGiGjVq5HT9tGnTtG/fPqf7VKhQwfHn8PBwSdLx48cz9kUB9xAqibBM7dq11aRJE8XExNxRdTAjdu3apYCAAOXLl8/R5ufn5/gX2meffaaKFStq0qRJ6tKli0tjAXKiXbt2qXjx4k5t+fPnV0REhCIiIjR79myVL19eVapUUWRk5L+ONXDgQHXq1En+/v4KDQ01JZ9+fn5On8+fP6/nn39eL730kmmsIkWKyMfHR7/99puWL1+un376SUOHDtXw4cO1fv16nT9/XpL0/fff67777nO69sbfhPb29nb8+XpMN77VDbgTkkRY6q233lKlSpVUqlQpp/YyZcpo9erVTm2rV6/WAw88IE9Pzwzd4/jx45o5c6Zat24tD4+bF889PDw0ePBg9evXT08//bR8fX0z9iDAPWzZsmXatm2b+vbte8s+hQsXVrt27RQTE6Nvv/32X8e7nlym10MPPaSdO3f+6zVeXl5q2LChGjZsqGHDhikoKEjLli1To0aNZLfbdejQIaep5Yzy8fG5o1kMICcjSYSlypcvrw4dOmjcuHFO7f3791fVqlX1+uuvq127doqPj9eHH36o8ePH/+t4hmEoISFBhmHo7Nmzio+P18iRIxUYGGjam/FGTzzxhAYOHKiPPvpIAwYMuOtnA3Ki5ORkJSQkKDU1VceOHdOiRYsUFxenFi1aqGPHjv96bZ8+fVSuXDlt2LDBNGV8NwYNGqTq1aurV69e6tq1q/z8/LRz504tXrxYH374oRYsWKD9+/erdu3ayps3r3744QelpaWpVKlSypMnjwYMGKC+ffsqLS1NDz/8sBITE7V69WoFBAQoOjo6XTEUK1ZMBw4c0ObNm1WoUCHlyZPHVIkE7jWsSYTlYmNjTVM6Dz30kL766it98cUXKleunIYOHarY2NjbTksnJSUpPDxc9913n6KiovTxxx8rOjpamzZtcqwxuhUvLy/16tVLo0ePdtpaA3AnixYtUnh4uIoVK6amTZvq559/1rhx4/Ttt9/etoofGRmpxo0ba+jQoZkaU4UKFbRixQr98ccfqlWrlh588EENHTpUBQsWlCQFBQVpzpw5ql+/vsqUKaOJEydq1qxZKlu2rCTp9ddf15AhQxQXF6cyZcqoadOm+v77703T5/+mbdu2atq0qerVq6cCBQpo1qxZmfqMQHZkM66v6AcAAAD+PyqJAAAAMCFJBAAAgAlJIgAAAExIEgEAAGBCkggAAAATkkQAAACYkCQCAADAhCQRAAAAJiSJADJNp06d1Lp1a8fnunXr6uWXX87yOJYvXy6bzaazZ8+67B43PuudyIo4AeBOkSQC97hOnTrJZrPJZrPJx8dHERERio2NVUpKisvvPWfOHL3++uvp6pvVCVOxYsX03nvvZcm9ACAn8rI6AACu17RpU02ePFnJycn64Ycf1LNnT3l7eysmJsbU98qVK/Lx8cmU+wYHB2fKOACArEclEXADdrtdYWFhKlq0qHr06KGGDRvqu+++k/R/06ZvvvmmChYsqFKlSkmS/vrrLz355JMKCgpScHCwWrVqpYMHDzrGTE1NVb9+/RQUFKR8+fLplVde0Y0/BX/jdHNycrIGDRqkwoULy263KyIiQpMmTdLBgwdVr149SVLevHlls9nUqVMnSVJaWpri4uJUvHhx+fr6qmLFivr666+d7vPDDz/ogQcekK+vr+rVq+cU551ITU1Vly5dHPcsVaqU3n///Zv2HTFihAoUKKCAgAC98MILunLliuNcemIHgOyKSiLghnx9fXXq1CnH56VLlyogIECLFy+WJF29elVNmjRRVFSUfvnlF3l5eemNN95Q06ZNtXXrVvn4+Ojdd9/VlClT9Nlnn6lMmTJ69913NXfuXNWvX/+W9+3YsaPi4+M1btw4VaxYUQcOHNDJkydVuHBhffPNN2rbtq12796tgIAA+fr6SpLi4uL0+eefa+LEiSpZsqRWrlypZ555RgUKFFCdOnX0119/qU2bNurZs6e6d++uDRs2qH///nf1/aSlpalQoUKaPXu28uXLpzVr1qh79+4KDw/Xk08+6fS95cqVS8uXL9fBgwfVuXNn5cuXT2+++Wa6YgeAbM0AcE+Ljo42WrVqZRiGYaSlpRmLFy827Ha7MWDAAMf50NBQIzk52XHN9OnTjVKlShlpaWmOtuTkZMPX19f48ccfDcMwjPDwcGP06NGO81evXjUKFSrkuJdhGEadOnWMPn36GIZhGLt37zYkGYsXL75pnD///LMhyThz5oyj7fLly0bu3LmNNWvWOPXt0qWL8dRTTxmGYRgxMTFGZGSk0/lBgwaZxrpR0aJFjbFjx97y/I169uxptG3b1vE5OjraCA4ONi5cuOBomzBhguHv72+kpqamK/abPTMAZBdUEgE3sGDBAvn7++vq1atKS0vT008/reHDhzvOly9f3mkd4pYtW7R3717lyZPHaZzLly9r3759SkxM1NGjR1WtWjXHOS8vL1WpUsU05Xzd5s2b5enpmaEK2t69e3Xx4kU1atTIqf3KlSt68MEHJUm7du1yikOSoqKi0n2PW/noo4/02Wef6dChQ7p06ZKuXLmiSpUqOfWpWLGicufO7XTf8+fP66+//tL58+dvGzsAZGckiYAbqFevniZMmCAfHx8VLFhQXl7Of/X9/PycPp8/f16VK1fWjBkzTGMVKFDgjmK4Pn2cEefPn5ckff/997rvvvucztnt9juKIz2++OILDRgwQO+++66ioqKUJ08evf3221q3bl26x7AqdgDILCSJgBvw8/NTREREuvs/9NBD+vLLLxUSEqKAgICb9gkPD9e6detUu3ZtSVJKSoo2btyohx566Kb9y5cvr7S0NK1YsUINGzY0nb9eyUxNTXW0RUZGym6369ChQ7esQJYpU8bxEs51a9euvf1D/ovVq1erRo0aevHFFx1t+/btM/XbsmWLLl265EiA165dK39/fxUuXFjBwcG3jR0AsjPebgZg0qFDB+XPn1+tWrXSL7/8ogMHDmj58uV66aWXdPjwYUlSnz599NZbb2nevHn6/fff9eKLL/7rHofFihVTdHS0nnvuOc2bN88x5ldffSVJKlq0qGw2mxYsWKATJ07o/PnzypMnjwYMGKC+fftq6tSp2rdvn3777Td98MEHmjp1qiTphRde0J49ezRw4EDt3r1bM2fO1JQpU9L1nH///bc2b97sdJw5c0YlS5bUhg0b9OOPP+qPP/7QkCFDtH79etP1V65cUZcuXbRz50798MMPGjZsmHr16iUPD490xQ4A2ZrViyIBuNY/X1zJyPmjR48aHTt2NPLnz2/Y7XajRIkSRrdu3YzExETDMK69qNKnTx8jICDACAoKMvr162d07Njxli+uGIZhXLp0yejbt68RHh5u+Pj4GBEREcZnn33mOB8bG2uEhYUZNpvNiI6ONgzj2ss27733nlGqVCnD29vbKFCggNGkSRNjxYoVjuvmz59vREREGHa73ahVq5bx2WefpevFFUmmY/r06cbly5eNTp06GYGBgUZQUJDRo0cP49VXXzUqVqxo+t6GDh1q5MuXz/D39ze6detmXL582dHndrHz4gqA7MxmGLdYZQ4AAAC3xXQzAAAATEgSAQAAYEKSCAAAABOSRAAAAJiQJAIAAMCEJBEAAAAmJIkAAAAwIUkEAACACUkiAAAATEgSAQAAYEKSCAAAAJP/B1iQVe0YcOgmAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell to unzip the manually uploaded file\n",
        "import os\n",
        "\n",
        "# Navigate to the correct directory\n",
        "IDRID_DIR = \"/content/drive/My Drive/Kaggle/IDRiD_Dataset\"\n",
        "%cd $IDRID_DIR\n",
        "\n",
        "# --- THIS IS THE FIX ---\n",
        "# Check for the specific filename you downloaded\n",
        "source_zip_file = \"archive (1).zip\"\n",
        "# --------------------\n",
        "\n",
        "if os.path.exists(source_zip_file):\n",
        "    # Rename it to be more descriptive (good practice)\n",
        "    os.rename(source_zip_file, \"idrid-dataset.zip\")\n",
        "    print(f\"Renamed '{source_zip_file}' to idrid-dataset.zip\")\n",
        "\n",
        "# Unzip the file\n",
        "print(\"\\nUnzipping the dataset...\")\n",
        "!unzip -q idrid-dataset.zip\n",
        "\n",
        "# Verify that the files are now there\n",
        "print(\"\\nVerification: Listing files in the directory...\")\n",
        "!ls\n",
        "\n",
        "print(\"\\n✅ Unzip complete! You are now ready to prepare the data for fine-tuning.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExMWM4B4E_cf",
        "outputId": "d3fee7e7-d952-4fed-9066-315c72ba3c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Kaggle/IDRiD_Dataset\n",
            "Renamed 'archive (1).zip' to idrid-dataset.zip\n",
            "\n",
            "Unzipping the dataset...\n",
            "\n",
            "Verification: Listing files in the directory...\n",
            "idrid-dataset.zip  idrid_labels.csv  Imagenes  kaggle.json\n",
            "\n",
            "✅ Unzip complete! You are now ready to prepare the data for fine-tuning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1 (Corrected): Prepare the IDRiD Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define the directory where you unzipped the data\n",
        "IDRID_DIR = \"/content/drive/My Drive/Kaggle/IDRiD_Dataset\"\n",
        "%cd $IDRID_DIR\n",
        "\n",
        "# --- THIS IS THE FIX ---\n",
        "# Update the path to point to the nested 'Imagenes' folder\n",
        "IDRID_LABEL_PATH = os.path.join(IDRID_DIR, 'idrid_labels.csv')\n",
        "IDRID_IMG_DIR = os.path.join(IDRID_DIR, 'Imagenes', 'Imagenes') # Corrected path\n",
        "# ----------------------\n",
        "\n",
        "# Load the labels\n",
        "idrid_df = pd.read_csv(IDRID_LABEL_PATH)\n",
        "\n",
        "# Clean up column names if needed\n",
        "if '# diagnosis' in idrid_df.columns:\n",
        "    idrid_df = idrid_df.rename(columns={'# diagnosis': 'diagnosis'})\n",
        "\n",
        "# Create the binary label (0 for No DR, 1 for DR Present)\n",
        "idrid_df['binary_diagnosis'] = idrid_df['diagnosis'].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "# Create full image paths\n",
        "idrid_df['image_path'] = idrid_df['id_code'].apply(lambda x: os.path.join(IDRID_IMG_DIR, f'{x}.jpg'))\n",
        "\n",
        "# --- Define constants and the preprocessing function ---\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def load_and_preprocess_image(path, label):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "    return image, label\n",
        "\n",
        "# Create the TensorFlow Dataset\n",
        "idrid_ds = tf.data.Dataset.from_tensor_slices((idrid_df['image_path'].values, idrid_df['binary_diagnosis'].values))\n",
        "idrid_ds = idrid_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "idrid_ds = idrid_ds.shuffle(buffer_size=len(idrid_df)).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "print(f\"\\n✅ IDRiD dataset with {len(idrid_df)} images is ready for specialization.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx9qWRiAGtdI",
        "outputId": "7260bbbe-5af3-425c-85f1-14027b75b21c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Kaggle/IDRiD_Dataset\n",
            "\n",
            "✅ IDRiD dataset with 455 images is ready for specialization.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell to find the correct folder structure\n",
        "!ls -R \"/content/drive/My Drive/Kaggle/IDRiD_Dataset\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF-CC-8zMSVv",
        "outputId": "2e159b2f-59bb-42c7-d922-9481d1e5ef43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/My Drive/Kaggle/IDRiD_Dataset':\n",
            "idrid-dataset.zip  idrid_labels.csv  Imagenes  kaggle.json\n",
            "\n",
            "'/content/drive/My Drive/Kaggle/IDRiD_Dataset/Imagenes':\n",
            "Imagenes\n",
            "\n",
            "'/content/drive/My Drive/Kaggle/IDRiD_Dataset/Imagenes/Imagenes':\n",
            "IDRiD_001.jpg\t   IDRiD_065.jpg      IDRiD_174.jpg  IDRiD_292.jpg\n",
            "IDRiD_001test.jpg  IDRiD_065test.jpg  IDRiD_175.jpg  IDRiD_293.jpg\n",
            "IDRiD_002.jpg\t   IDRiD_066.jpg      IDRiD_176.jpg  IDRiD_294.jpg\n",
            "IDRiD_003.jpg\t   IDRiD_066test.jpg  IDRiD_177.jpg  IDRiD_295.jpg\n",
            "IDRiD_004.jpg\t   IDRiD_067.jpg      IDRiD_178.jpg  IDRiD_296.jpg\n",
            "IDRiD_004test.jpg  IDRiD_067test.jpg  IDRiD_179.jpg  IDRiD_297.jpg\n",
            "IDRiD_005.jpg\t   IDRiD_068.jpg      IDRiD_180.jpg  IDRiD_298.jpg\n",
            "IDRiD_005test.jpg  IDRiD_068test.jpg  IDRiD_181.jpg  IDRiD_299.jpg\n",
            "IDRiD_006.jpg\t   IDRiD_069.jpg      IDRiD_182.jpg  IDRiD_300.jpg\n",
            "IDRiD_006test.jpg  IDRiD_069test.jpg  IDRiD_184.jpg  IDRiD_301.jpg\n",
            "IDRiD_007.jpg\t   IDRiD_070.jpg      IDRiD_185.jpg  IDRiD_302.jpg\n",
            "IDRiD_007test.jpg  IDRiD_071.jpg      IDRiD_186.jpg  IDRiD_303.jpg\n",
            "IDRiD_008.jpg\t   IDRiD_072.jpg      IDRiD_187.jpg  IDRiD_304.jpg\n",
            "IDRiD_008test.jpg  IDRiD_072test.jpg  IDRiD_188.jpg  IDRiD_305.jpg\n",
            "IDRiD_009.jpg\t   IDRiD_073.jpg      IDRiD_189.jpg  IDRiD_306.jpg\n",
            "IDRiD_009test.jpg  IDRiD_073test.jpg  IDRiD_190.jpg  IDRiD_307.jpg\n",
            "IDRiD_010.jpg\t   IDRiD_074.jpg      IDRiD_191.jpg  IDRiD_308.jpg\n",
            "IDRiD_010test.jpg  IDRiD_074test.jpg  IDRiD_192.jpg  IDRiD_309.jpg\n",
            "IDRiD_011.jpg\t   IDRiD_075.jpg      IDRiD_193.jpg  IDRiD_310.jpg\n",
            "IDRiD_011test.jpg  IDRiD_076.jpg      IDRiD_194.jpg  IDRiD_311.jpg\n",
            "IDRiD_012.jpg\t   IDRiD_076test.jpg  IDRiD_195.jpg  IDRiD_312.jpg\n",
            "IDRiD_012test.jpg  IDRiD_077.jpg      IDRiD_196.jpg  IDRiD_313.jpg\n",
            "IDRiD_013.jpg\t   IDRiD_078.jpg      IDRiD_197.jpg  IDRiD_314.jpg\n",
            "IDRiD_013test.jpg  IDRiD_078test.jpg  IDRiD_198.jpg  IDRiD_315.jpg\n",
            "IDRiD_014.jpg\t   IDRiD_079.jpg      IDRiD_199.jpg  IDRiD_316.jpg\n",
            "IDRiD_014test.jpg  IDRiD_079test.jpg  IDRiD_200.jpg  IDRiD_317.jpg\n",
            "IDRiD_015.jpg\t   IDRiD_080.jpg      IDRiD_201.jpg  IDRiD_318.jpg\n",
            "IDRiD_015test.jpg  IDRiD_080test.jpg  IDRiD_202.jpg  IDRiD_319.jpg\n",
            "IDRiD_016.jpg\t   IDRiD_081.jpg      IDRiD_203.jpg  IDRiD_320.jpg\n",
            "IDRiD_016test.jpg  IDRiD_081test.jpg  IDRiD_204.jpg  IDRiD_321.jpg\n",
            "IDRiD_017.jpg\t   IDRiD_082.jpg      IDRiD_205.jpg  IDRiD_322.jpg\n",
            "IDRiD_017test.jpg  IDRiD_082test.jpg  IDRiD_206.jpg  IDRiD_323.jpg\n",
            "IDRiD_018.jpg\t   IDRiD_083.jpg      IDRiD_207.jpg  IDRiD_324.jpg\n",
            "IDRiD_018test.jpg  IDRiD_083test.jpg  IDRiD_208.jpg  IDRiD_325.jpg\n",
            "IDRiD_019.jpg\t   IDRiD_084.jpg      IDRiD_209.jpg  IDRiD_326.jpg\n",
            "IDRiD_019test.jpg  IDRiD_084test.jpg  IDRiD_210.jpg  IDRiD_327.jpg\n",
            "IDRiD_020.jpg\t   IDRiD_085.jpg      IDRiD_211.jpg  IDRiD_328.jpg\n",
            "IDRiD_020test.jpg  IDRiD_085test.jpg  IDRiD_212.jpg  IDRiD_329.jpg\n",
            "IDRiD_021test.jpg  IDRiD_086.jpg      IDRiD_213.jpg  IDRiD_330.jpg\n",
            "IDRiD_022.jpg\t   IDRiD_086test.jpg  IDRiD_214.jpg  IDRiD_331.jpg\n",
            "IDRiD_022test.jpg  IDRiD_087.jpg      IDRiD_215.jpg  IDRiD_332.jpg\n",
            "IDRiD_023.jpg\t   IDRiD_087test.jpg  IDRiD_217.jpg  IDRiD_333.jpg\n",
            "IDRiD_023test.jpg  IDRiD_088.jpg      IDRiD_218.jpg  IDRiD_334.jpg\n",
            "IDRiD_024.jpg\t   IDRiD_088test.jpg  IDRiD_219.jpg  IDRiD_335.jpg\n",
            "IDRiD_024test.jpg  IDRiD_089.jpg      IDRiD_220.jpg  IDRiD_337.jpg\n",
            "IDRiD_025.jpg\t   IDRiD_089test.jpg  IDRiD_221.jpg  IDRiD_338.jpg\n",
            "IDRiD_025test.jpg  IDRiD_090.jpg      IDRiD_222.jpg  IDRiD_339.jpg\n",
            "IDRiD_026.jpg\t   IDRiD_090test.jpg  IDRiD_223.jpg  IDRiD_340.jpg\n",
            "IDRiD_026test.jpg  IDRiD_091.jpg      IDRiD_224.jpg  IDRiD_341.jpg\n",
            "IDRiD_027.jpg\t   IDRiD_091test.jpg  IDRiD_225.jpg  IDRiD_342.jpg\n",
            "IDRiD_027test.jpg  IDRiD_092.jpg      IDRiD_226.jpg  IDRiD_343.jpg\n",
            "IDRiD_028.jpg\t   IDRiD_093.jpg      IDRiD_227.jpg  IDRiD_344.jpg\n",
            "IDRiD_028test.jpg  IDRiD_094.jpg      IDRiD_228.jpg  IDRiD_345.jpg\n",
            "IDRiD_029.jpg\t   IDRiD_095.jpg      IDRiD_229.jpg  IDRiD_347.jpg\n",
            "IDRiD_029test.jpg  IDRiD_096.jpg      IDRiD_230.jpg  IDRiD_348.jpg\n",
            "IDRiD_030.jpg\t   IDRiD_096test.jpg  IDRiD_231.jpg  IDRiD_349.jpg\n",
            "IDRiD_030test.jpg  IDRiD_097.jpg      IDRiD_232.jpg  IDRiD_350.jpg\n",
            "IDRiD_031.jpg\t   IDRiD_098.jpg      IDRiD_233.jpg  IDRiD_353.jpg\n",
            "IDRiD_031test.jpg  IDRiD_099.jpg      IDRiD_234.jpg  IDRiD_354.jpg\n",
            "IDRiD_032.jpg\t   IDRiD_100.jpg      IDRiD_235.jpg  IDRiD_356.jpg\n",
            "IDRiD_032test.jpg  IDRiD_100test.jpg  IDRiD_236.jpg  IDRiD_357.jpg\n",
            "IDRiD_033.jpg\t   IDRiD_101.jpg      IDRiD_237.jpg  IDRiD_358.jpg\n",
            "IDRiD_033test.jpg  IDRiD_101test.jpg  IDRiD_238.jpg  IDRiD_360.jpg\n",
            "IDRiD_034.jpg\t   IDRiD_102.jpg      IDRiD_239.jpg  IDRiD_361.jpg\n",
            "IDRiD_034test.jpg  IDRiD_102test.jpg  IDRiD_240.jpg  IDRiD_362.jpg\n",
            "IDRiD_035.jpg\t   IDRiD_103.jpg      IDRiD_241.jpg  IDRiD_363.jpg\n",
            "IDRiD_035test.jpg  IDRiD_103test.jpg  IDRiD_242.jpg  IDRiD_364.jpg\n",
            "IDRiD_036test.jpg  IDRiD_104.jpg      IDRiD_243.jpg  IDRiD_365.jpg\n",
            "IDRiD_037.jpg\t   IDRiD_105.jpg      IDRiD_244.jpg  IDRiD_366.jpg\n",
            "IDRiD_037test.jpg  IDRiD_106.jpg      IDRiD_245.jpg  IDRiD_367.jpg\n",
            "IDRiD_038.jpg\t   IDRiD_107.jpg      IDRiD_246.jpg  IDRiD_368.jpg\n",
            "IDRiD_038test.jpg  IDRiD_108.jpg      IDRiD_247.jpg  IDRiD_369.jpg\n",
            "IDRiD_039.jpg\t   IDRiD_109.jpg      IDRiD_248.jpg  IDRiD_370.jpg\n",
            "IDRiD_040.jpg\t   IDRiD_111.jpg      IDRiD_249.jpg  IDRiD_371.jpg\n",
            "IDRiD_040test.jpg  IDRiD_112.jpg      IDRiD_250.jpg  IDRiD_372.jpg\n",
            "IDRiD_041.jpg\t   IDRiD_113.jpg      IDRiD_251.jpg  IDRiD_374.jpg\n",
            "IDRiD_042.jpg\t   IDRiD_114.jpg      IDRiD_252.jpg  IDRiD_375.jpg\n",
            "IDRiD_042test.jpg  IDRiD_115.jpg      IDRiD_253.jpg  IDRiD_376.jpg\n",
            "IDRiD_043.jpg\t   IDRiD_116.jpg      IDRiD_254.jpg  IDRiD_377.jpg\n",
            "IDRiD_044.jpg\t   IDRiD_117.jpg      IDRiD_255.jpg  IDRiD_378.jpg\n",
            "IDRiD_044test.jpg  IDRiD_118.jpg      IDRiD_256.jpg  IDRiD_379.jpg\n",
            "IDRiD_045.jpg\t   IDRiD_119.jpg      IDRiD_257.jpg  IDRiD_380.jpg\n",
            "IDRiD_046.jpg\t   IDRiD_121.jpg      IDRiD_258.jpg  IDRiD_381.jpg\n",
            "IDRiD_047.jpg\t   IDRiD_122.jpg      IDRiD_259.jpg  IDRiD_383.jpg\n",
            "IDRiD_048.jpg\t   IDRiD_123.jpg      IDRiD_260.jpg  IDRiD_384.jpg\n",
            "IDRiD_048test.jpg  IDRiD_124.jpg      IDRiD_261.jpg  IDRiD_385.jpg\n",
            "IDRiD_049.jpg\t   IDRiD_125.jpg      IDRiD_262.jpg  IDRiD_386.jpg\n",
            "IDRiD_049test.jpg  IDRiD_126.jpg      IDRiD_263.jpg  IDRiD_387.jpg\n",
            "IDRiD_050.jpg\t   IDRiD_127.jpg      IDRiD_264.jpg  IDRiD_388.jpg\n",
            "IDRiD_051.jpg\t   IDRiD_128.jpg      IDRiD_266.jpg  IDRiD_389.jpg\n",
            "IDRiD_051test.jpg  IDRiD_129.jpg      IDRiD_267.jpg  IDRiD_390.jpg\n",
            "IDRiD_052.jpg\t   IDRiD_130.jpg      IDRiD_268.jpg  IDRiD_391.jpg\n",
            "IDRiD_053.jpg\t   IDRiD_131.jpg      IDRiD_269.jpg  IDRiD_392.jpg\n",
            "IDRiD_053test.jpg  IDRiD_132.jpg      IDRiD_270.jpg  IDRiD_393.jpg\n",
            "IDRiD_054.jpg\t   IDRiD_133.jpg      IDRiD_271.jpg  IDRiD_394.jpg\n",
            "IDRiD_055.jpg\t   IDRiD_134.jpg      IDRiD_272.jpg  IDRiD_396.jpg\n",
            "IDRiD_055test.jpg  IDRiD_135.jpg      IDRiD_273.jpg  IDRiD_397.jpg\n",
            "IDRiD_056.jpg\t   IDRiD_136.jpg      IDRiD_274.jpg  IDRiD_398.jpg\n",
            "IDRiD_057.jpg\t   IDRiD_137.jpg      IDRiD_275.jpg  IDRiD_399.jpg\n",
            "IDRiD_057test.jpg  IDRiD_139.jpg      IDRiD_276.jpg  IDRiD_400.jpg\n",
            "IDRiD_058.jpg\t   IDRiD_140.jpg      IDRiD_278.jpg  IDRiD_401.jpg\n",
            "IDRiD_058test.jpg  IDRiD_143.jpg      IDRiD_279.jpg  IDRiD_402.jpg\n",
            "IDRiD_059.jpg\t   IDRiD_144.jpg      IDRiD_280.jpg  IDRiD_403.jpg\n",
            "IDRiD_059test.jpg  IDRiD_152.jpg      IDRiD_281.jpg  IDRiD_404.jpg\n",
            "IDRiD_060.jpg\t   IDRiD_154.jpg      IDRiD_282.jpg  IDRiD_405.jpg\n",
            "IDRiD_060test.jpg  IDRiD_155.jpg      IDRiD_283.jpg  IDRiD_406.jpg\n",
            "IDRiD_061.jpg\t   IDRiD_156.jpg      IDRiD_284.jpg  IDRiD_407.jpg\n",
            "IDRiD_061test.jpg  IDRiD_157.jpg      IDRiD_285.jpg  IDRiD_408.jpg\n",
            "IDRiD_062.jpg\t   IDRiD_158.jpg      IDRiD_286.jpg  IDRiD_409.jpg\n",
            "IDRiD_062test.jpg  IDRiD_160.jpg      IDRiD_287.jpg  IDRiD_410.jpg\n",
            "IDRiD_063.jpg\t   IDRiD_165.jpg      IDRiD_288.jpg  IDRiD_411.jpg\n",
            "IDRiD_063test.jpg  IDRiD_166.jpg      IDRiD_289.jpg  IDRiD_412.jpg\n",
            "IDRiD_064.jpg\t   IDRiD_167.jpg      IDRiD_290.jpg  IDRiD_413.jpg\n",
            "IDRiD_064test.jpg  IDRiD_172.jpg      IDRiD_291.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Final Specialization and Saving\n",
        "from tensorflow import keras\n",
        "\n",
        "# Define the path to your best model from the APTOS training\n",
        "APTOS_MODEL_PATH = '/content/drive/MyDrive/binary_model_checkpoint.keras'\n",
        "\n",
        "# Load your powerful \"generalist\" model\n",
        "print(f\"Loading best model from: {APTOS_MODEL_PATH}\")\n",
        "model = keras.models.load_model(APTOS_MODEL_PATH)\n",
        "\n",
        "# Re-compile the model with an extremely low learning rate for gentle fine-tuning\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-6), # Extremely low learning rate\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\n--- Starting Final Fine-Tuning on IDRiD Dataset ---\")\n",
        "\n",
        "# Train for just a few epochs to specialize the model's knowledge\n",
        "history_final = model.fit(\n",
        "    idrid_ds,\n",
        "    epochs=10 # Train for a small number of epochs on the new data\n",
        ")\n",
        "\n",
        "# --- Save the Final, Specialized Model ---\n",
        "FINAL_MODEL_PATH = '/content/drive/MyDrive/final_specialized_netra_ai_model.h5'\n",
        "model.save(FINAL_MODEL_PATH)\n",
        "\n",
        "print(f\"\\n🎉🎉🎉 Final, specialized model is trained and saved!\")\n",
        "print(f\"You can find your ultimate model at: {FINAL_MODEL_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "pMEIk__lLmmE",
        "outputId": "5727e0f6-b6aa-460a-d790-966b425ec273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading best model from: /content/drive/MyDrive/binary_model_checkpoint.keras\n",
            "\n",
            "--- Starting Final Fine-Tuning on IDRiD Dataset ---\n",
            "Epoch 1/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 3s/step - accuracy: 0.8143 - loss: 0.4710\n",
            "Epoch 2/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 3s/step - accuracy: 0.7826 - loss: 0.6055\n",
            "Epoch 3/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.8266 - loss: 0.4795\n",
            "Epoch 4/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.8218 - loss: 0.4210\n",
            "Epoch 5/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.7869 - loss: 0.5104\n",
            "Epoch 6/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 3s/step - accuracy: 0.8105 - loss: 0.5432\n",
            "Epoch 7/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 3s/step - accuracy: 0.8088 - loss: 0.5270\n",
            "Epoch 8/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 3s/step - accuracy: 0.7825 - loss: 0.5660\n",
            "Epoch 9/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 3s/step - accuracy: 0.8041 - loss: 0.4982\n",
            "Epoch 10/10\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 3s/step - accuracy: 0.8258 - loss: 0.4803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "cannot pickle 'module' object",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1985451342.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# --- Save the Final, Specialized Model ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mFINAL_MODEL_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/final_specialized_netra_ai_model.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFINAL_MODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n🎉🎉🎉 Final, specialized model is trained and saved!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mappend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    160\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    160\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_tuple\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_deepcopy_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;31m# We're not going to put the tuple in the memo, but it's still important we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;31m# check for it, in case the tuple contains recursive mutable structures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_list\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mappend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    160\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__setstate__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    149\u001b[0m                     \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce_ex__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreductor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                         \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreductor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                         \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'module' object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell to correctly save the final model\n",
        "\n",
        "# --- THIS IS THE FIX ---\n",
        "# We are changing the file extension from .h5 to .keras\n",
        "FINAL_MODEL_PATH = '/content/drive/MyDrive/final_specialized_netra_ai_model.keras'\n",
        "# ----------------------\n",
        "\n",
        "print(f\"Saving the final, specialized model to the recommended '.keras' format...\")\n",
        "model.save(FINAL_MODEL_PATH)\n",
        "\n",
        "print(f\"\\n✅ Final, specialized model successfully saved!\")\n",
        "print(f\"You can find your ultimate model at: {FINAL_MODEL_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owSEdFRacLnT",
        "outputId": "efee8911-2a5e-4ea0-a793-95dd9e135cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving the final, specialized model to the recommended '.keras' format...\n",
            "\n",
            "✅ Final, specialized model successfully saved!\n",
            "You can find your ultimate model at: /content/drive/MyDrive/final_specialized_netra_ai_model.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Prepare the Validation Dataset\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the base directory for the full APTOS dataset\n",
        "DATA_DIR = \"/content/drive/My Drive/Kaggle/APTOS2019_Full\"\n",
        "TRAIN_IMG_DIR = os.path.join(DATA_DIR, \"train_images\")\n",
        "\n",
        "# Load the csv file\n",
        "df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
        "\n",
        "# Create the binary label\n",
        "df['binary_diagnosis'] = df['diagnosis'].apply(lambda x: 1 if x > 0 else 0)\n",
        "df['image_path'] = df['id_code'].apply(lambda x: os.path.join(TRAIN_IMG_DIR, f'{x}.png'))\n",
        "\n",
        "# Split the data (we only need the validation part)\n",
        "_, val_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['binary_diagnosis']\n",
        ")\n",
        "\n",
        "# --- Define constants and preprocessing ---\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def load_and_preprocess_image(path, label):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
        "    return image, label\n",
        "\n",
        "# Create the validation dataset\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_df['image_path'].values, val_df['binary_diagnosis'].values))\n",
        "val_ds = val_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"✅ APTOS validation dataset is ready for evaluation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLDyBuModQtM",
        "outputId": "11dbad69-74aa-472e-9fed-af55c393bc88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ APTOS validation dataset is ready for evaluation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Evaluate the Final Specialized Model\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "\n",
        "# --- 1. LOAD YOUR FINAL SPECIALIZED MODEL ---\n",
        "FINAL_MODEL_PATH = '/content/drive/MyDrive/final_specialized_netra_ai_model.keras'\n",
        "print(f\"Loading best model from: {FINAL_MODEL_PATH}\")\n",
        "model = tf.keras.models.load_model(FINAL_MODEL_PATH)\n",
        "\n",
        "# --- 2. MAKE PREDICTIONS ON THE VALIDATION SET ---\n",
        "print(\"Making predictions on the validation set...\")\n",
        "y_true = np.concatenate([y for x, y in val_ds], axis=0)\n",
        "y_pred_proba = model.predict(val_ds)\n",
        "y_pred = (y_pred_proba > 0.5).astype(\"int32\").flatten()\n",
        "\n",
        "# --- 3. PRINT THE CLASSIFICATION REPORT ---\n",
        "print(\"\\n--- Classification Report ---\")\n",
        "target_names = ['No DR', 'DR Present']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))\n",
        "\n",
        "# --- 4. CALCULATE AND PRINT THE F1-SCORE EXPLICITLY ---\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "print(f\"\\nMacro Average F1-Score: {f1:.4f}\")\n",
        "print(\"The F1-Score is the harmonic mean of precision and recall, providing a single metric that balances both concerns.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPXC7pmMdS57",
        "outputId": "26a360b2-a23d-4df5-bb3c-225543888aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading best model from: /content/drive/MyDrive/final_specialized_netra_ai_model.keras\n",
            "Making predictions on the validation set...\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 4s/step\n",
            "\n",
            "--- Classification Report ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       No DR       0.93      0.99      0.96       361\n",
            "  DR Present       0.99      0.93      0.96       372\n",
            "\n",
            "    accuracy                           0.96       733\n",
            "   macro avg       0.96      0.96      0.96       733\n",
            "weighted avg       0.96      0.96      0.96       733\n",
            "\n",
            "\n",
            "Macro Average F1-Score: 0.9604\n",
            "The F1-Score is the harmonic mean of precision and recall, providing a single metric that balances both concerns.\n"
          ]
        }
      ]
    }
  ]
}